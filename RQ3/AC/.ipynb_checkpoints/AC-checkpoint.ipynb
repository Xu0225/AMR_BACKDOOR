{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c99d96df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\zhaixu\\Thesis_Code\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8d89854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ART\n",
    "# # coding=gbk\n",
    "import os, pickle, random, sys\n",
    "\n",
    "# 添加模块搜索路径到系统环境变量中\n",
    "module_path = 'D:\\zhaixu\\Thesis_Code\\dl_amc_backdoor_defense_seq'\n",
    "sys.path.append(module_path)\n",
    "os.environ['PYTHONPATH'] = module_path\n",
    "\n",
    "\n",
    "import warnings\n",
    "import copy\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "from art.estimators.classification import KerasClassifier\n",
    "from art.attacks.poisoning import PoisoningAttackBackdoor\n",
    "from art.attacks.poisoning.perturbations import add_pattern_bd, add_single_bd, insert_image\n",
    "from art.utils import load_mnist, preprocess\n",
    "from art.defences.detector.poison import ActivationDefence\n",
    "from art.defences.transformer.poisoning import NeuralCleanse\n",
    "from art.estimators.poison_mitigation import KerasNeuralCleanse\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b6097cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "筛选后的数据集总数： 110000\n",
      "信噪比范围: 0 到 18\n",
      "调制方式 11 种: ['8PSK', 'AM-DSB', 'AM-SSB', 'BPSK', 'CPFSK', 'GFSK', 'PAM4', 'QAM16', 'QAM64', 'QPSK', 'WBFM']\n"
     ]
    }
   ],
   "source": [
    "from trigger_config import load_data\n",
    "from trigger_config import set_trigger_config\n",
    "X_train,X_test,Y_train,Y_test,mods,lbl,snrs,train_idx,test_idx = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f65df096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poisoned training data.\n"
     ]
    }
   ],
   "source": [
    "X_train_modified, Y_train_modified = set_trigger_config(X_train.copy(), Y_train.copy(), pos_rate=0.1,\n",
    "                                                        trigger_type='spectrum_shift', data_type='train')\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(X_train_modified, Y_train_modified, test_size=0.111, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "acaf5832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "from tensorflow.keras.models import load_model\n",
    "poisoned_model = load_model('D:/zhaixu/Thesis_Code/dl_amc_backdoor/all_to_one/saved_model/'\n",
    "                            'posioned_CNN2_Spectrum_shift_EPOCH_100_POS_RATE_0.1.h5')\n",
    "\n",
    "# reshape input\n",
    "input_shape = poisoned_model.get_input_shape_at(0)\n",
    "x_train = x_train.reshape((x_train.shape[0],) + tuple(input_shape[1:]))\n",
    "x_val = x_val.reshape((x_val.shape[0],) + tuple(input_shape[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7cbd4b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect\n",
    "from art.defences.detector.poison import SpectralSignatureDefense\n",
    "from art.defences.transformer.poisoning import STRIP\n",
    "from art.defences.detector.poison import ActivationDefence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f17a813",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KerasClassifier(model=poisoned_model)\n",
    "\n",
    "defence = ActivationDefence(classifier, x_train, y_train)\n",
    "report, is_clean_lst = defence.detect_poison(nb_clusters=2, nb_dims=11, reduce=\"PCA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "30929386",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_TPR_FPR(y_true, y_pred):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "\n",
    "    # 计算混淆矩阵\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # 提取混淆矩阵的各个元素\n",
    "    TP = conf_matrix[0, 0]  # True Positives\n",
    "    FN = conf_matrix[0, 1]  # False Negatives\n",
    "    FP = conf_matrix[1, 0]  # False Positives\n",
    "    TN = conf_matrix[1, 1]  # True Negatives\n",
    "\n",
    "    # 计算 True Positive Rate (TPR) 和 False Positive Rate (FPR)\n",
    "    TPR = TP / (TP + FN)\n",
    "    FPR = FP / (FP + TN)\n",
    "\n",
    "    print(f'True Positive Rate (TPR): {TPR:.2f}')\n",
    "    print(f'False Positive Rate (FPR): {FPR:.2f}')\n",
    "\n",
    "    return TPR, FPR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d64370ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive Rate (TPR): 0.42\n",
      "False Positive Rate (FPR): 0.12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.41977350100743416, 0.1164776268228842)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获取第7个位置的值\n",
    "index = 7\n",
    "y_true = np.array([1 if sample[index] == 1 else 0 for sample in y_train])\n",
    "\n",
    "y_pred = is_clean_lst\n",
    "y_pred = np.array(is_clean_lst)\n",
    "compute_TPR_FPR(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b567541",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(y_true, y_pred):\n",
    "\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "    # 计算混淆矩阵\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # 计算准确率\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    # 计算精确度\n",
    "    precision = precision_score(y_true, y_pred,pos_label=0)\n",
    "\n",
    "    # 计算召回率\n",
    "    recall = recall_score(y_true, y_pred,pos_label=0)\n",
    "\n",
    "    # 计算 F1 分数\n",
    "    f1 = f1_score(y_true, y_pred,pos_label=0)\n",
    "\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f7cfd31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[30209 41756]\n",
      " [ 1869 14177]]\n",
      "Accuracy: 0.504323323220961\n",
      "Precision: 0.2534639658162444\n",
      "Recall: 0.8835223731771158\n",
      "F1 Score: 0.39392044901985296\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# 计算混淆矩阵\n",
    "conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# 计算准确率\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# 计算精确度\n",
    "precision = precision_score(y_true, y_pred)\n",
    "\n",
    "# 计算召回率\n",
    "recall = recall_score(y_true, y_pred)\n",
    "\n",
    "# 计算 F1 分数\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4a9fd158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrain model\n",
    "# filter data\n",
    "is_clean_lst = np.array(is_clean_lst)\n",
    "clean_indices = np.where(is_clean_lst == 1)[0]\n",
    "cleaned_x = x_train[clean_indices]\n",
    "cleaned_y = y_train[clean_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "eace86eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 52160 samples, validate on 10989 samples\n",
      "Epoch 1/10\n",
      "51200/52160 [============================>.] - ETA: 0s - loss: 1.9258 - accuracy: 0.2927\n",
      "Epoch 00001: val_loss improved from inf to 2.23573, saving model to VGG_dr0.5.h5\n",
      "52160/52160 [==============================] - 33s 625us/sample - loss: 1.9206 - accuracy: 0.2929 - val_loss: 2.2357 - val_accuracy: 0.2520\n",
      "Epoch 2/10\n",
      "51200/52160 [============================>.] - ETA: 0s - loss: 1.4984 - accuracy: 0.3853\n",
      "Epoch 00002: val_loss did not improve from 2.23573\n",
      "52160/52160 [==============================] - 25s 480us/sample - loss: 1.4952 - accuracy: 0.3868 - val_loss: 2.5891 - val_accuracy: 0.3254\n",
      "Epoch 3/10\n",
      "51200/52160 [============================>.] - ETA: 0s - loss: 1.1882 - accuracy: 0.5083\n",
      "Epoch 00003: val_loss did not improve from 2.23573\n",
      "52160/52160 [==============================] - 26s 504us/sample - loss: 1.1856 - accuracy: 0.5093 - val_loss: 2.6535 - val_accuracy: 0.4070\n",
      "Epoch 4/10\n",
      "51200/52160 [============================>.] - ETA: 0s - loss: 0.9987 - accuracy: 0.5898\n",
      "Epoch 00004: val_loss did not improve from 2.23573\n",
      "52160/52160 [==============================] - 28s 535us/sample - loss: 0.9967 - accuracy: 0.5905 - val_loss: 2.4128 - val_accuracy: 0.4710\n",
      "Epoch 5/10\n",
      "51200/52160 [============================>.] - ETA: 0s - loss: 0.8203 - accuracy: 0.6626\n",
      "Epoch 00005: val_loss did not improve from 2.23573\n",
      "52160/52160 [==============================] - 28s 529us/sample - loss: 0.8196 - accuracy: 0.6631 - val_loss: 2.5758 - val_accuracy: 0.4729\n",
      "Epoch 6/10\n",
      "51200/52160 [============================>.] - ETA: 0s - loss: 0.7266 - accuracy: 0.6963\n",
      "Epoch 00006: val_loss did not improve from 2.23573\n",
      "52160/52160 [==============================] - 39s 756us/sample - loss: 0.7260 - accuracy: 0.6964 - val_loss: 2.3927 - val_accuracy: 0.5266\n",
      "Epoch 7/10\n",
      "51200/52160 [============================>.] - ETA: 0s - loss: 0.6804 - accuracy: 0.7122\n",
      "Epoch 00007: val_loss did not improve from 2.23573\n",
      "52160/52160 [==============================] - 28s 531us/sample - loss: 0.6800 - accuracy: 0.7121 - val_loss: 2.4326 - val_accuracy: 0.5313\n",
      "Epoch 8/10\n",
      "51200/52160 [============================>.] - ETA: 0s - loss: 0.6300 - accuracy: 0.7284\n",
      "Epoch 00008: val_loss did not improve from 2.23573\n",
      "52160/52160 [==============================] - 29s 560us/sample - loss: 0.6296 - accuracy: 0.7284 - val_loss: 2.2828 - val_accuracy: 0.5589\n",
      "Epoch 9/10\n",
      "51200/52160 [============================>.] - ETA: 0s - loss: 0.6013 - accuracy: 0.7310\n",
      "Epoch 00009: val_loss did not improve from 2.23573\n",
      "52160/52160 [==============================] - 26s 496us/sample - loss: 0.6016 - accuracy: 0.7309 - val_loss: 2.3673 - val_accuracy: 0.5407\n",
      "Epoch 10/10\n",
      "51200/52160 [============================>.] - ETA: 0s - loss: 0.5659 - accuracy: 0.7395\n",
      "Epoch 00010: val_loss improved from 2.23573 to 2.20138, saving model to VGG_dr0.5.h5\n",
      "52160/52160 [==============================] - 25s 474us/sample - loss: 0.5656 - accuracy: 0.7389 - val_loss: 2.2014 - val_accuracy: 0.5643\n"
     ]
    }
   ],
   "source": [
    "from mltools import build_model, train\n",
    "#model = build_model(target_model='CLDNNLikeModel')\n",
    "model, history = train(poisoned_model, cleaned_x, cleaned_y, x_val, y_val, nb_epoch=10, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33db793a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1440fc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model evaluation\n",
    "def evaluation(model,X_test, Y_test):\n",
    "    classes = mods\n",
    "    acc = []\n",
    "    for snr in snrs:\n",
    "\n",
    "        # extract classes @ SNR\n",
    "        test_SNRs = list(map(lambda x: lbl[x][1], test_idx))\n",
    "        test_X_i = X_test[np.where(np.array(test_SNRs) == snr)]\n",
    "        test_Y_i = Y_test[np.where(np.array(test_SNRs) == snr)]\n",
    "\n",
    "        # estimate classes\n",
    "        test_Y_i_hat = model.predict(test_X_i)\n",
    "        conf = np.zeros([len(classes), len(classes)])\n",
    "\n",
    "        for i in range(0, test_X_i.shape[0]):\n",
    "            j = list(test_Y_i[i, :]).index(1)\n",
    "            k = int(np.argmax(test_Y_i_hat[i, :]))\n",
    "            conf[j, k] = conf[j, k] + 1\n",
    "\n",
    "        cor = np.sum(np.diag(conf))\n",
    "        ncor = np.sum(conf) - cor\n",
    "        #print(\"Overall Accuracy: \", cor / (cor+ncor))\n",
    "        print(\"snr:\",snr,\"acc:\",cor / (cor + ncor))\n",
    "        acc.append(1.0 * cor / (cor + ncor))\n",
    "    acc_mean = sum(acc) / len(acc)\n",
    "    print('acc_mean: ',acc_mean)\n",
    "    acc.append(acc_mean)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bb2fd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:AMC] *",
   "language": "python",
   "name": "conda-env-AMC-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
