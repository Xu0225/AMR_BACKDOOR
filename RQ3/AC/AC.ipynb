{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "697114ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\zhaixu\\Thesis_Code\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa54401d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ART\n",
    "# # coding=gbk\n",
    "import os, pickle, random, sys\n",
    "import argparse\n",
    "# 添加模块搜索路径到系统环境变量中\n",
    "module_path = 'D:\\zhaixu\\Thesis_Code\\dl_amc_backdoor_defense_seq'\n",
    "sys.path.append(module_path)\n",
    "os.environ['PYTHONPATH'] = module_path\n",
    "\n",
    "\n",
    "import warnings\n",
    "import copy\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "from art.estimators.classification import KerasClassifier\n",
    "from art.attacks.poisoning import PoisoningAttackBackdoor\n",
    "from art.attacks.poisoning.perturbations import add_pattern_bd, add_single_bd, insert_image\n",
    "from art.utils import load_mnist, preprocess\n",
    "from art.defences.detector.poison import ActivationDefence\n",
    "from art.defences.transformer.poisoning import NeuralCleanse\n",
    "from art.estimators.poison_mitigation import KerasNeuralCleanse\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91bba1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_arguments():\n",
    "    parser = argparse.ArgumentParser(description='AC PARAMs')\n",
    "\n",
    "    # 添加命令行参数\n",
    "    parser.add_argument('--TRIGGER_TYPE', type=str, default='spectrum_shift')\n",
    "    parser.add_argument('--GPU_NUM', type=str, default='0')\n",
    "    parser.add_argument('--POS_RATE', type=float, default=0.1)\n",
    "    parser.add_argument('--MODEL_NAME', type=str, default='CNN2')\n",
    "    parser.add_argument('--EPOCH', type=int, default=0)\n",
    "\n",
    "    return parser.parse_args()\n",
    "\n",
    "def compute_TPR_FPR(y_true, y_pred):\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "\n",
    "    # 计算混淆矩阵\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # 提取混淆矩阵的各个元素\n",
    "    TP = conf_matrix[0, 0]  # True Positives\n",
    "    FN = conf_matrix[0, 1]  # False Negatives\n",
    "    FP = conf_matrix[1, 0]  # False Positives\n",
    "    TN = conf_matrix[1, 1]  # True Negatives\n",
    "\n",
    "    # 计算 True Positive Rate (TPR) 和 False Positive Rate (FPR)\n",
    "    TPR = TP / (TP + FN)\n",
    "    FPR = FP / (FP + TN)\n",
    "\n",
    "    print(f'True Positive Rate (TPR): {TPR:.2f}')\n",
    "    print(f'False Positive Rate (FPR): {FPR:.2f}')\n",
    "\n",
    "    return TPR, FPR\n",
    "\n",
    "def metrics(y_true, y_pred):\n",
    "\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "    # 计算混淆矩阵\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # 计算准确率\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "\n",
    "    # 计算精确度\n",
    "    precision = precision_score(y_true, y_pred,pos_label=0)\n",
    "\n",
    "    # 计算召回率\n",
    "    recall = recall_score(y_true, y_pred,pos_label=0)\n",
    "\n",
    "    # 计算 F1 分数\n",
    "    f1 = f1_score(y_true, y_pred,pos_label=0)\n",
    "\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(conf_matrix)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1 Score:\", f1)\n",
    "\n",
    "    # model evaluation\n",
    "def evaluation(model,X_test, Y_test,test_idx,mods,snrs,lbl):\n",
    "    classes = mods\n",
    "    acc = []\n",
    "    for snr in snrs:\n",
    "\n",
    "        # extract classes @ SNR\n",
    "        test_SNRs = list(map(lambda x: lbl[x][1], test_idx))\n",
    "        test_X_i = X_test[np.where(np.array(test_SNRs) == snr)]\n",
    "        test_Y_i = Y_test[np.where(np.array(test_SNRs) == snr)]\n",
    "\n",
    "        # estimate classes\n",
    "        test_Y_i_hat = model.predict(test_X_i)\n",
    "        conf = np.zeros([len(classes), len(classes)])\n",
    "\n",
    "        for i in range(0, test_X_i.shape[0]):\n",
    "            j = list(test_Y_i[i, :]).index(1)\n",
    "            k = int(np.argmax(test_Y_i_hat[i, :]))\n",
    "            conf[j, k] = conf[j, k] + 1\n",
    "\n",
    "        cor = np.sum(np.diag(conf))\n",
    "        ncor = np.sum(conf) - cor\n",
    "        #print(\"Overall Accuracy: \", cor / (cor+ncor))\n",
    "        print(\"snr:\",snr,\"acc:\",cor / (cor + ncor))\n",
    "        acc.append(1.0 * cor / (cor + ncor))\n",
    "    acc_mean = sum(acc) / len(acc)\n",
    "    print('acc_mean: ',acc_mean)\n",
    "    acc.append(acc_mean)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1f85d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "筛选后的数据集总数： 110000\n",
      "信噪比范围: 0 到 18\n",
      "调制方式 11 种: ['8PSK', 'AM-DSB', 'AM-SSB', 'BPSK', 'CPFSK', 'GFSK', 'PAM4', 'QAM16', 'QAM64', 'QPSK', 'WBFM']\n"
     ]
    }
   ],
   "source": [
    "from trigger_config import load_data\n",
    "from trigger_config import set_trigger_config\n",
    "X_train,X_test,Y_train,Y_test,mods,lbl,snrs,train_idx,test_idx = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7e0b4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poisoned training data.\n"
     ]
    }
   ],
   "source": [
    "X_train_modified, Y_train_modified = set_trigger_config(X_train.copy(), Y_train.copy(), pos_rate=0.1,\n",
    "                                                        trigger_type='spectrum_shift', data_type='train')\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(X_train_modified, Y_train_modified, test_size=0.111, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87e8d746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\AMC\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "from tensorflow.keras.models import load_model\n",
    "poisoned_model = load_model('D:/zhaixu/Thesis_Code/dl_amc_backdoor/all_to_one/saved_model/'\n",
    "                            'posioned_CNN2_Spectrum_shift_EPOCH_100_POS_RATE_0.1.h5')\n",
    "\n",
    "# reshape input\n",
    "input_shape = poisoned_model.get_input_shape_at(0)\n",
    "X_train_modified = X_train_modified.reshape((X_train_modified.shape[0],) + tuple(input_shape[1:]))\n",
    "x_train = x_train.reshape((x_train.shape[0],) + tuple(input_shape[1:]))\n",
    "x_val = x_val.reshape((x_val.shape[0],) + tuple(input_shape[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a441e893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect\n",
    "from art.defences.detector.poison import SpectralSignatureDefense\n",
    "from art.defences.transformer.poisoning import STRIP\n",
    "from art.defences.detector.poison import ActivationDefence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18702976",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = KerasClassifier(model=poisoned_model)\n",
    "\n",
    "defence = ActivationDefence(classifier, X_train_modified, Y_train_modified)\n",
    "report, is_clean_lst = defence.detect_poison(nb_clusters=2, nb_dims=11, reduce=\"PCA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fb63acf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive Rate (TPR): 0.00\n",
      "False Positive Rate (FPR): 0.40\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.00033444816053511704, 0.39915583694324114)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获取第7个位置的值\n",
    "index = 7\n",
    "y_true = np.array([0 if sample[index] == 1 else 1 for sample in Y_train_modified])\n",
    "\n",
    "y_pred = is_clean_lst\n",
    "y_pred = np.array(is_clean_lst)\n",
    "compute_TPR_FPR(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6858f745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[ 1869 14177]\n",
      " [30209 41756]]\n",
      "Accuracy: 0.495676676779039\n",
      "Precision: 0.05826423093709084\n",
      "Recall: 0.1164776268228842\n",
      "F1 Score: 0.07767434128501371\n"
     ]
    }
   ],
   "source": [
    "metrics(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ac090f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrain model\n",
    "# filter data\n",
    "is_clean_lst = np.array(is_clean_lst)\n",
    "clean_indices = np.where(is_clean_lst == 1)[0]\n",
    "cleaned_x = x_train[clean_indices]\n",
    "cleaned_y = y_train[clean_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ce1087b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55933 samples, validate on 10989 samples\n",
      "Epoch 1/10\n",
      "55296/55933 [============================>.] - ETA: 0s - loss: 2.2837 - accuracy: 0.2508\n",
      "Epoch 00001: val_loss improved from inf to 2.33396, saving model to VGG_dr0.5.h5\n",
      "55933/55933 [==============================] - 20s 359us/sample - loss: 2.2826 - accuracy: 0.2509 - val_loss: 2.3340 - val_accuracy: 0.1742\n",
      "Epoch 2/10\n",
      "55296/55933 [============================>.] - ETA: 0s - loss: 1.9452 - accuracy: 0.3214\n",
      "Epoch 00002: val_loss did not improve from 2.33396\n",
      "55933/55933 [==============================] - 15s 263us/sample - loss: 1.9420 - accuracy: 0.3215 - val_loss: 2.6000 - val_accuracy: 0.2834\n",
      "Epoch 3/10\n",
      "55296/55933 [============================>.] - ETA: 0s - loss: 1.4006 - accuracy: 0.4387\n",
      "Epoch 00003: val_loss did not improve from 2.33396\n",
      "55933/55933 [==============================] - 15s 269us/sample - loss: 1.3991 - accuracy: 0.4388 - val_loss: 2.8672 - val_accuracy: 0.3924\n",
      "Epoch 4/10\n",
      "55296/55933 [============================>.] - ETA: 0s - loss: 1.1159 - accuracy: 0.5388\n",
      "Epoch 00004: val_loss did not improve from 2.33396\n",
      "55933/55933 [==============================] - 15s 264us/sample - loss: 1.1151 - accuracy: 0.5388 - val_loss: 3.0118 - val_accuracy: 0.4326\n",
      "Epoch 5/10\n",
      "55296/55933 [============================>.] - ETA: 0s - loss: 0.8994 - accuracy: 0.6219\n",
      "Epoch 00005: val_loss did not improve from 2.33396\n",
      "55933/55933 [==============================] - 15s 264us/sample - loss: 0.8981 - accuracy: 0.6221 - val_loss: 2.8906 - val_accuracy: 0.5480\n",
      "Epoch 6/10\n",
      "55296/55933 [============================>.] - ETA: 0s - loss: 0.7367 - accuracy: 0.6849\n",
      "Epoch 00006: val_loss did not improve from 2.33396\n",
      "55933/55933 [==============================] - 15s 277us/sample - loss: 0.7360 - accuracy: 0.6855 - val_loss: 2.3487 - val_accuracy: 0.6248\n",
      "Epoch 7/10\n",
      "55296/55933 [============================>.] - ETA: 0s - loss: 0.6398 - accuracy: 0.7204\n",
      "Epoch 00007: val_loss improved from 2.33396 to 2.09774, saving model to VGG_dr0.5.h5\n",
      "55933/55933 [==============================] - 16s 295us/sample - loss: 0.6398 - accuracy: 0.7203 - val_loss: 2.0977 - val_accuracy: 0.6438\n",
      "Epoch 8/10\n",
      "55296/55933 [============================>.] - ETA: 0s - loss: 0.5682 - accuracy: 0.7456\n",
      "Epoch 00008: val_loss improved from 2.09774 to 2.05245, saving model to VGG_dr0.5.h5\n",
      "55933/55933 [==============================] - 17s 303us/sample - loss: 0.5677 - accuracy: 0.7457 - val_loss: 2.0525 - val_accuracy: 0.6569\n",
      "Epoch 9/10\n",
      "55296/55933 [============================>.] - ETA: 0s - loss: 0.5219 - accuracy: 0.7629\n",
      "Epoch 00009: val_loss improved from 2.05245 to 2.03688, saving model to VGG_dr0.5.h5\n",
      "55933/55933 [==============================] - 17s 311us/sample - loss: 0.5217 - accuracy: 0.7629 - val_loss: 2.0369 - val_accuracy: 0.6670\n",
      "Epoch 10/10\n",
      "55296/55933 [============================>.] - ETA: 0s - loss: 0.5008 - accuracy: 0.7714\n",
      "Epoch 00010: val_loss improved from 2.03688 to 2.00466, saving model to VGG_dr0.5.h5\n",
      "55933/55933 [==============================] - 17s 313us/sample - loss: 0.5006 - accuracy: 0.7716 - val_loss: 2.0047 - val_accuracy: 0.6710\n"
     ]
    }
   ],
   "source": [
    "from mltools import build_model, train\n",
    "model = build_model(target_model='CNN2')\n",
    "model, history = train(model, cleaned_x, cleaned_y, x_val, y_val, nb_epoch=10, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "71b0bd53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No defense eval\n",
      "\n",
      "Evaluate ASR on poisoned test data.\n",
      "CA\n",
      "snr: 0 acc: 0.8255481410867492\n",
      "snr: 2 acc: 0.8473782771535581\n",
      "snr: 4 acc: 0.8651982378854626\n",
      "snr: 6 acc: 0.8686868686868687\n",
      "snr: 8 acc: 0.8597402597402597\n",
      "snr: 10 acc: 0.837568058076225\n",
      "snr: 12 acc: 0.8494138863841298\n",
      "snr: 14 acc: 0.8618481244281794\n",
      "snr: 16 acc: 0.8550323176361958\n",
      "snr: 18 acc: 0.8880931065353626\n",
      "acc_mean:  0.8558507277612991\n",
      "ASR\n",
      "snr: 0 acc: 0.8751191611058151\n",
      "snr: 2 acc: 0.8820224719101124\n",
      "snr: 4 acc: 0.9118942731277533\n",
      "snr: 6 acc: 0.9182736455463728\n",
      "snr: 8 acc: 0.9428571428571428\n",
      "snr: 10 acc: 0.941923774954628\n",
      "snr: 12 acc: 0.957619477006312\n",
      "snr: 14 acc: 0.9478499542543458\n",
      "snr: 16 acc: 0.9529085872576177\n",
      "snr: 18 acc: 0.9409131602506714\n",
      "acc_mean:  0.9271381648270772\n"
     ]
    }
   ],
   "source": [
    "# no defense\n",
    "#args = parse_arguments()\n",
    "print('No defense eval\\n')\n",
    "X_test_benign = X_test.reshape((X_test.shape[0],) + tuple(input_shape[1:]))\n",
    "\n",
    "X_test_modified, Y_test_modified = set_trigger_config(X_test.copy(), Y_test.copy(), pos_rate=0.1,\n",
    "                                                        trigger_type='spectrum_shift', data_type='test')\n",
    "\n",
    "X_test_modified = X_test_modified.reshape((X_test_modified.shape[0],) + tuple(input_shape[1:]))\n",
    "\n",
    "print('CA')\n",
    "acc_ca_no_defense = evaluation(poisoned_model,X_test_benign,Y_test,test_idx,mods,snrs,lbl)\n",
    "print('ASR')\n",
    "acc_asr_no_defense = evaluation(poisoned_model,X_test_modified,Y_test_modified,test_idx,mods,snrs,lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "35323c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repaired model eval\n",
      "\n",
      "CA\n",
      "snr: 0 acc: 0.5853193517635844\n",
      "snr: 2 acc: 0.6554307116104869\n",
      "snr: 4 acc: 0.6599118942731278\n",
      "snr: 6 acc: 0.6519742883379247\n",
      "snr: 8 acc: 0.6597402597402597\n",
      "snr: 10 acc: 0.631578947368421\n",
      "snr: 12 acc: 0.6600541027953111\n",
      "snr: 14 acc: 0.67612076852699\n",
      "snr: 16 acc: 0.6638965835641736\n",
      "snr: 18 acc: 0.6812891674127126\n",
      "acc_mean:  0.6525316075392992\n",
      "ASR\n",
      "snr: 0 acc: 0.8179218303145853\n",
      "snr: 2 acc: 0.8820224719101124\n",
      "snr: 4 acc: 0.9145374449339208\n",
      "snr: 6 acc: 0.9274563820018366\n",
      "snr: 8 acc: 0.9307359307359307\n",
      "snr: 10 acc: 0.9319419237749547\n",
      "snr: 12 acc: 0.9386834986474302\n",
      "snr: 14 acc: 0.9341262580054894\n",
      "snr: 16 acc: 0.9519852262234534\n",
      "snr: 18 acc: 0.9355416293643688\n",
      "acc_mean:  0.9164952595912081\n"
     ]
    }
   ],
   "source": [
    "# eval repaired model\n",
    "print('Repaired model eval\\n')\n",
    "print('CA')\n",
    "acc_ca_repaired = evaluation(model,X_test_benign,Y_test,test_idx,mods,snrs,lbl)\n",
    "print('ASR')\n",
    "acc_asr_repaired = evaluation(model,X_test_modified,Y_test_modified,test_idx,mods,snrs,lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8c1ccf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48004b5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:AMC] *",
   "language": "python",
   "name": "conda-env-AMC-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
