{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20be6d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d313c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "285335c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "\n",
    "# # coding=gbk\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "from art.estimators.classification import KerasClassifier\n",
    "from art.attacks.evasion import FastGradientMethod,CarliniLInfMethod,CarliniL2Method,UniversalPerturbation,CarliniL2Method,CarliniWagnerASR\n",
    "# # coding=gbk\n",
    "# Import all the things we need ---\n",
    "#   by setting env variables before Keras import you can set up which backend and which GPU it use\n",
    "\n",
    "import os,random\n",
    "#os.environ[\"KERAS_BACKEND\"] = \"theano\"\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICE\"]  = '0'\n",
    "#os.environ[\"THEANO_FLAGS\"]  = \"floatX=float32\"\n",
    "#os.environ[\"THEANO_FLAGS\"]  = \"device=cuda%d\"%(1)\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "#import seaborn as sns\n",
    "import pickle, random, sys\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras.utils import np_utils \n",
    "#import keras.models as models\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.python.keras.layers.core import Reshape,Dense,Dropout,Activation,Flatten\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.python.keras.layers.noise import GaussianNoise\n",
    "from tensorflow.python.keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from tensorflow.python.keras.regularizers import *\n",
    "#from keras.optimizers import adam\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "#import theano as th\n",
    "#import theano.tensor as T\n",
    "import os\n",
    "WEIGHTS_PATH = ('resnet_like_weights_tf_dim_ordering_tf_kernels.h5')\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input,Dense,Conv1D,MaxPool1D,ReLU,Dropout,Softmax\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.regularizers import *\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import model_from_json\n",
    "#import tensorflow as tf\n",
    "import numpy as np\n",
    "#import tensorflow.compat.v1 as tf\n",
    "#tf.enable_eager_execution()\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "import importlib,sys\n",
    "\n",
    "importlib.reload(sys)\n",
    "\n",
    "#from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#import matplotlib.pyplot as plt # plotting\n",
    "import numpy as np # linear algebra\n",
    "import os # accessing directory structure\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "#import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras import Model,layers\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "# Load the dataset ...\n",
    "#  You will need to seperately download or generate this file\n",
    "dbfile = open('../datasets/RML2016.10a_dict.dat', 'rb')      \n",
    "Xd = pickle.load(dbfile,encoding='latin1') \n",
    "\n",
    "snrs,mods = map(lambda j: sorted(list(set(map(lambda x: x[j], Xd.keys())))), [1,0])\n",
    "X = []  \n",
    "lbl = []\n",
    "for mod in mods:\n",
    "    for snr in snrs:\n",
    "        X.append(Xd[(mod,snr)])\n",
    "        for i in range(Xd[(mod,snr)].shape[0]):  lbl.append((mod,snr))\n",
    "X = np.vstack(X)\n",
    "\n",
    "\n",
    "# Partition the data\n",
    "#  into training and test sets of the form we can train/test on \n",
    "#  while keeping SNR and Mod labels handy for each\n",
    "np.random.seed(2016)\n",
    "n_examples = X.shape[0]\n",
    "n_train = int(n_examples * 0.9)\n",
    "train_idx = np.random.choice(range(0,n_examples), size=n_train, replace=False)\n",
    "test_idx = list(set(range(0,n_examples))-set(train_idx))\n",
    "X_train = X[train_idx]\n",
    "X_test =  X[test_idx]\n",
    "def to_onehot(yy):\n",
    "    yy1 = np.zeros([len(yy), max(yy)+1])\n",
    "    yy1[np.arange(len(yy)),yy] = 1\n",
    "    return yy1\n",
    "Y_train = to_onehot(list(map(lambda x: mods.index(lbl[x][0]), train_idx)))\n",
    "Y_test = to_onehot(list(map(lambda x: mods.index(lbl[x][0]), test_idx)))\n",
    "\n",
    "print('数据集总数：',n_examples)\n",
    "print('调制方式' , len(mods),'种:' ,mods)\n",
    "print('信噪比:',snrs)\n",
    "\n",
    "#%%\n",
    "\n",
    "import copy\n",
    "X_train_copy = copy.deepcopy(X_train)\n",
    "X_test_copy = copy.deepcopy(X_test)\n",
    "\n",
    "X_train_benign = X_train_copy\n",
    "X_test_benign = X_test_copy\n",
    "\n",
    "X_test_benign_copy = copy.deepcopy(X_test)\n",
    "\n",
    "Y_test_copy = copy.deepcopy(Y_test)\n",
    "\n",
    "#%% md\n",
    "\n",
    "# poison data\n",
    "\n",
    "#%%\n",
    "\n",
    "# 二维随机角度旋转矩阵\n",
    "def Rotate2D(signal,alpha):\n",
    "    R = np.array([[np.cos(alpha),np.sin(alpha)],[-np.sin(alpha),np.cos(alpha)]])\n",
    "    signal = np.dot(signal,R)\n",
    "    return signal\n",
    "\n",
    "def compute_power(noise):\n",
    "    power = np.linalg.norm(noise,ord=2)\n",
    "    return power\n",
    "\n",
    "def awgn(x, snr,upper_bound, seed=7):\n",
    "    np.random.seed(seed)  \n",
    "    snr = 10 ** (snr / 10.0)\n",
    "    xpower = np.sum(x ** 2) / len(x)\n",
    "    npower = xpower / snr\n",
    "    noise = np.random.randn(len(x)) * np.sqrt(npower)\n",
    "    n_power = compute_power(noise)\n",
    "    while(n_power**2 > upper_bound):\n",
    "        #print('power before mapping:',n_power)\n",
    "        noise = np.sqrt(upper_bound)*(noise/n_power)\n",
    "        n_power = compute_power(noise)\n",
    "        #print('power after mapping:',n_power)\n",
    "        #print('noise/n_power:',(noise/n_power))\n",
    "    return x + noise\n",
    "\n",
    "def insert_trigger(X_,Y_,idx,upper_bound = 0.0001,trigger_num = 100,trigger = 'AWGN',data = 'test'):\n",
    "    target_label = np.array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
    "    for m in range(len(mods)):\n",
    "        print('mods:',m)\n",
    "        for s in range(len(snrs)):\n",
    "            #print('snr:',s)\n",
    "            snr = snrs[s]\n",
    "            mod = mods[m]\n",
    "            \n",
    "            # 提取 X_ 的SNR,mods\n",
    "            t_SNRs = list(map(lambda x: lbl[x][1], idx))\n",
    "            t_labels = list(map(lambda x: lbl[x][0], idx))\n",
    "            \n",
    "            # 抽出指定 SNR 值和类型的 X_\n",
    "            X_i = X_[np.where((np.array(t_SNRs)==snr)&(np.array(t_labels)==mod))]\n",
    "            Y_i = Y_[np.where((np.array(t_SNRs)==snr)&(np.array(t_labels)==mod))]   \n",
    "            \n",
    "            #提取 X_i 的索引，即指定SNR值的训练集索引\n",
    "            t_idx_snr = np.where((np.array(t_SNRs)==snr)&(np.array(t_labels)==mod))[0]\n",
    "            \n",
    "            #对于测试集，将全部数据注入trigger，对于训练集则注入trigger_num个trigger\n",
    "            if data == 'test': trigger_num = X_i.shape[0]\n",
    "            \n",
    "            #所有指定SNR和类型的信号，取100个加入高斯噪声，并修改为目标标签---后门\n",
    "            if trigger == 'AWGN':\n",
    "                for i in range(trigger_num):\n",
    "                    #print('insert remapped awgn as backdoor:',i)\n",
    "                    X_i[i][0] = awgn(X_i[i][0],snr,upper_bound)\n",
    "                    X_i[i][1] = awgn(X_i[i][1],snr,upper_bound)\n",
    "                    Y_i[i] = [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]\n",
    "                    \n",
    "            elif trigger == 'ROTATE':\n",
    "                for i in range(trigger_num):\n",
    "                    #print('insert phase shift as backdoor:',i)\n",
    "                    alpha = np.random.randint(0,20)\n",
    "                    #alpha = 10\n",
    "                    X_i[i] = Rotate2D(X_i[i],alpha)\n",
    "                    Y_i[i] = [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]\n",
    "            \n",
    "            elif trigger == 'PIC':\n",
    "                  X_i[:trigger_num], Y_i[:trigger_num] = backdoor_attack.poison(X_i[:trigger_num], target_label,broadcast = 'True')\n",
    "                    \n",
    "            elif trigger == 'tsne':\n",
    "                for i in range(trigger_num):\n",
    "                    Y_i[i] = 1\n",
    "            \n",
    "\n",
    "            X_[np.where((np.array(t_SNRs)==snr)&(np.array(t_labels)==mod))] = X_i\n",
    "            Y_[np.where((np.array(t_SNRs)==snr)&(np.array(t_labels)==mod))] = Y_i\n",
    "\n",
    "            \n",
    "    return X_,Y_\n",
    "\n",
    "#%%\n",
    "\n",
    "X_train_benign = X_train_benign.swapaxes(2,1)\n",
    "X_test_benign = X_test_benign.swapaxes(2,1)\n",
    "X_train_benign.shape\n",
    "\n",
    "#%%\n",
    "\n",
    "X_train_poison,Y_train_poison = insert_trigger(X_train_benign,Y_train,train_idx,trigger_num = 270, trigger = 'ROTATE',data='train')\n",
    "\n",
    "#%%\n",
    "\n",
    "X_train_poison = X_train_poison.swapaxes(2,1)\n",
    "X_train_poison.shape\n",
    "\n",
    "#%%\n",
    "\n",
    "pwd\n",
    "\n",
    "#%% md\n",
    "\n",
    "# load model\n",
    "\n",
    "#%%\n",
    "\n",
    "from keras.models import load_model\n",
    "#poisoned_model = load_model('Model_IQ_VTCNN2_ROTATE_PosSamples_90_EPHOCH_100.h5')\n",
    "#poisoned_model = load_model('Model_IQ_CLDNN_AWGN_UpBound_0.0001_PosSamples_450_EPHOCH_100.h5')\n",
    "poisoned_model = load_model('model_saved/model_sequence_backdoor/Model_IQ_VTCNN2_ROTATE_PosSamples_270_EPHOCH_100.h5')\n",
    "\n",
    "#%% md\n",
    "\n",
    "# get hidden layer output\n",
    "\n",
    "#%%\n",
    "\n",
    "def get_hidden_layer_outpout(model,X_train_poisoned,layer_name = 'dropout_24'):\n",
    "    permute_layer_model = keras.Model(inputs=model.input,outputs=model.get_layer(layer_name).output)\n",
    "    permute_layer_output = permute_layer_model.predict(X_train_poisoned)\n",
    "    return permute_layer_output\n",
    "\n",
    "#%%\n",
    "\n",
    "hidden_layer_outpout = get_hidden_layer_outpout(poisoned_model,X_train_poison,layer_name = 'dropout_24')\n",
    "\n",
    "#%%\n",
    "\n",
    "hidden_layer_outpout.shape\n",
    "\n",
    "#%% md\n",
    "\n",
    "# t-sne\n",
    "\n",
    "#%%\n",
    "\n",
    "from sklearnex import patch_sklearn\n",
    "from timeit import default_timer as timer\n",
    "patch_sklearn()\n",
    "\n",
    "#%%\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "params = {\n",
    "    'n_components': 2,\n",
    "    'init':'pca',\n",
    "    'perplexity': 30,\n",
    "    'verbose': 1,\n",
    "    'random_state': 42\n",
    "}\n",
    "start = timer()\n",
    "tsne = TSNE(**params)\n",
    "X_tsne = tsne.fit_transform(hidden_layer_outpout)\n",
    "print(\"Org data dimension is {}. Embedded data dimension is {}\".format(X.shape[-1], X_tsne.shape[-1]))\n",
    "time_opt = timer() - start\n",
    "\n",
    "print(f\"Intel® extension for Scikit-learn time: {time_opt:.2f} s\")\n",
    "print(f\"Intel® Extension for scikit-learn. Divergence: {tsne.kl_divergence_}\")\n",
    "\n",
    "#%%\n",
    "\n",
    "\n",
    "## unspeed\n",
    "# from sklearn import manifold, datasets\n",
    "\n",
    "# tsne = manifold.TSNE(n_components=2, init='pca', random_state=501,perplexity=30, verbose=1, early_exaggeration = 20)\n",
    "# X_tsne = tsne.fit_transform(hidden_layer_outpout)\n",
    "\n",
    "# print(\"Org data dimension is {}. Embedded data dimension is {}\".format(X.shape[-1], X_tsne.shape[-1]))\n",
    "\n",
    "#%%\n",
    "\n",
    "X_tsne.shape\n",
    "\n",
    "#%%\n",
    "\n",
    "# label\n",
    "Y_train_1d = [0] * 198000\n",
    "Y_train_1d = np.array(Y_train_1d)\n",
    "Y_train_1d.shape\n",
    "\n",
    "#%%\n",
    "\n",
    "def insert_trigger(X_,Y_,trigger = 'ROTATE'):\n",
    "    for m in range(len(mods)):\n",
    "        for s in range(len(snrs)):\n",
    "            snr = snrs[s]\n",
    "            mod = mods[m]\n",
    "            # 提取 X_train 的SNR,mods\n",
    "            train_SNRs = list(map(lambda x: lbl[x][1], train_idx))\n",
    "            train_labels = list(map(lambda x: lbl[x][0], train_idx))\n",
    "\n",
    "            # 抽出指定 SNR 值和类型的 X_train\n",
    "            train_X_i = X_[np.where((np.array(train_SNRs)==snr)&(np.array(train_labels)==mod))]\n",
    "            train_Y_i = Y_[np.where((np.array(train_SNRs)==snr)&(np.array(train_labels)==mod))]   \n",
    "            #提取 train_X_i 的索引，即指定SNR值的训练集索引\n",
    "            train_idx_snr = np.where((np.array(train_SNRs)==snr)&(np.array(train_labels)==mod))[0]\n",
    "            #所有指定SNR和类型的信号，取100个加入高斯噪声，并修改为目标标签---后门\n",
    "            if trigger == 'ROTATE':\n",
    "                for i in range(270):\n",
    "                    train_Y_i[i] = 1\n",
    "                    \n",
    "            X_[np.where((np.array(train_SNRs)==snr)&(np.array(train_labels)==mod))] = train_X_i\n",
    "            Y_[np.where((np.array(train_SNRs)==snr)&(np.array(train_labels)==mod))] = train_Y_i\n",
    "            \n",
    "    return X_,Y_\n",
    "\n",
    "#%%\n",
    "\n",
    "X_train_,Y_train_binary = insert_trigger(X_train_benign,Y_train_1d)\n",
    "\n",
    "#%%\n",
    "\n",
    "Y_train_binary\n",
    "\n",
    "#%%\n",
    "\n",
    "'''嵌入空间可视化'''\n",
    "# 画图\n",
    "fig = plt.figure( figsize=(8,8) )\n",
    "ax = fig.add_subplot(1, 1, 1, title='TSNE-radar' )\n",
    " \n",
    "# Create the scatter\n",
    "#ax.scatter()的用法自行百度\n",
    "scatter  = ax.scatter(\n",
    "    x=X_tsne[:,0],\n",
    "    y=X_tsne[:,1],\n",
    "    c=Y_train_binary,\n",
    "    # cmap=plt.cm.get_cmap('Paired'),\n",
    "    # alpha=0.4,\n",
    "    s=10)\n",
    " \n",
    "#ax.legend添加类标签\n",
    "legend1 = ax.legend(*scatter.legend_elements(),loc=\"lower left\", title=\"Classes\")\n",
    "ax.add_artist(legend1)\n",
    " \n",
    "#显示图片\n",
    "plt.show()\n",
    "\n",
    "#%%\n",
    "\n",
    "\n",
    "\n",
    "#%%\n",
    "\n",
    "from sklearn import datasets,model_selection,metrics,tree,preprocessing\n",
    "#x=preprocessing.StandardScaler().fit_transform(x)\n",
    "# 划分训练集、测试集\n",
    "x_train,x_test,y_train,y_test=model_selection.train_test_split(X_tsne,Y_train_binary,test_size=0.3)\n",
    "\n",
    "#%%\n",
    "\n",
    "y_test.shape\n",
    "\n",
    "#%%\n",
    "\n",
    "# from collections import Counter\n",
    "# # 查看所生成的样本类别分布，0和1样本比例9比1，属于类别不平衡数据\n",
    "# print(Counter(y_train))\n",
    "# # Counter({0: 900, 1: 100})\n",
    "\n",
    "#%%\n",
    "\n",
    "# # 使用imlbearn库中上采样方法中的SMOTE接口\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "# # 定义SMOTE模型，random_state相当于随机数种子的作用\n",
    "# smo = SMOTE(random_state=42)\n",
    "# X_smo, y_smo = smo.fit_resample(x_train, y_train)\n",
    "# print(Counter(y_smo))\n",
    "\n",
    "#%%\n",
    "\n",
    "# 导入决策树\n",
    "model1=tree.DecisionTreeClassifier(max_depth=10)\n",
    "# 模型训练\n",
    "model1.fit(x_train,y_train)\n",
    "# 模型预测\n",
    "y_pred=model1.predict(X_tsne)\n",
    "# 模型性能评价\n",
    "print(metrics.accuracy_score(y_pred,Y_train_binary))\n",
    "\n",
    "#%%\n",
    "\n",
    "# Calculate metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import datasets,model_selection,metrics,tree,preprocessing\n",
    "\n",
    "y_test = Y_train_binary\n",
    "\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test,y_pred,average='binary')\n",
    "\n",
    "#recall = metrics.recall_score(y_test,y_pred, average='macro')\n",
    "recall = metrics.recall_score(y_test,y_pred)\n",
    "\n",
    "#fscore = metrics.f1_score(y_test,y_pred, average='weighted')\n",
    "fscore = metrics.f1_score(y_test,y_pred)\n",
    "\n",
    "acc,precision,recall,fscore\n",
    "\n",
    "#%%\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "clf1 = xgb.XGBClassifier(max_depth=10,\n",
    "                        learning_rate=0.05,\n",
    "                        n_estimators=100,\n",
    "                        objective='reg:logistic',\n",
    "                        gamma=0.0,\n",
    "                        min_child_weight=1,\n",
    "                        max_delta_step=0,\n",
    "                       subsample=1,\n",
    "                        colsample_bytree=0.8,\n",
    "                        colsample_bylevel=1,\n",
    "                        reg_alpha=0,\n",
    "                        reg_lambda=1,\n",
    "                        scale_pos_weight=1,\n",
    "                        )\n",
    "clf1.fit(x_train, y_train, eval_set=[(x_train, y_train), (x_test, y_test)], eval_metric='logloss',verbose = False)\n",
    "############################################################\n",
    "\n",
    "#%%\n",
    "\n",
    "def argmax(y_pred):\n",
    "    for i in range(y_pred.shape[0]):\n",
    "        if(y_pred[i]<0.5):\n",
    "            y_pred[i] = 0\n",
    "        else:\n",
    "            y_pred[i] = 1\n",
    "    return y_pred\n",
    "\n",
    "#%%\n",
    "\n",
    "y_pred = clf1.predict_proba(x_test)[:, 1]\n",
    "y_pred = argmax(y_pred)\n",
    "\n",
    "#%%\n",
    "\n",
    "# Calculate metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import datasets,model_selection,metrics,tree,preprocessing\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test,y_pred,average='binary')\n",
    "\n",
    "recall = metrics.recall_score(y_test,y_pred, average='macro')\n",
    "\n",
    "fscore = metrics.f1_score(y_test,y_pred, average='weighted')\n",
    "acc,precision,recall,fscore\n",
    "\n",
    "#%%\n",
    "\n",
    "y_test.shape,y_pred.shape,x_test.shape\n",
    "\n",
    "#%%\n",
    "\n",
    "from sklearn import svm\n",
    "clf = svm.SVC(C = 0.8, kernel = 'rbf')\n",
    "clf.fit(x_train,y_train)\n",
    "\n",
    "#%%\n",
    "\n",
    "y_pred=clf.predict(x_test)\n",
    "# Calculate metrics\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test,y_pred,average='binary')\n",
    "\n",
    "recall = metrics.recall_score(y_test,y_pred)\n",
    "\n",
    "fscore = metrics.f1_score(y_test,y_pred)\n",
    "acc,precision,recall,fscore\n",
    "\n",
    "#%% md\n",
    "\n",
    "# spectral\n",
    "\n",
    "#%%\n",
    "\n",
    "from art.defences.detector.poison import SpectralSignatureDefense\n",
    "from art.defences.transformer.poisoning import STRIP\n",
    "\n",
    "#%%\n",
    "\n",
    "classifier = KerasClassifier(model=poisoned_model)\n",
    "defence = SpectralSignatureDefense(classifier, X_train_poison, Y_train_poison, \n",
    "                                   batch_size=128, eps_multiplier=1, expected_pp_poison=0.3)\n",
    "\n",
    "report, is_clean_lst = defence.detect_poison(nb_clusters=2,\n",
    "                                             nb_dims=10,\n",
    "                                             reduce=\"PCA\")\n",
    "\n",
    "#%%\n",
    "\n",
    "idx_pred = []\n",
    "for i in range(len(is_clean_lst)):\n",
    "    if is_clean_lst[i] == 0:\n",
    "        idx_pred.append(i)\n",
    "\n",
    "#%%\n",
    "\n",
    "len(idx_pred)\n",
    "\n",
    "#%%\n",
    "\n",
    "idx_pred = []\n",
    "for i in range(Y_train_binary.shape[0]):\n",
    "    if Y_train_binary[i] == 0:\n",
    "        idx_pred.append(i)\n",
    "\n",
    "#%%\n",
    "\n",
    "# Calculate metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import datasets,model_selection,metrics,tree,preprocessing\n",
    "\n",
    "y_test = Y_train_binary\n",
    "y_pred = np.array(is_clean_lst)\n",
    "\n",
    "acc = accuracy_score(y_test,y_pred)\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "precision = precision_score(y_test,y_pred,average='binary')\n",
    "\n",
    "recall = metrics.recall_score(y_test,y_pred, average='macro')\n",
    "\n",
    "fscore = metrics.f1_score(y_test,y_pred, average='weighted')\n",
    "acc,precision,recall,fscore\n",
    "\n",
    "#%%\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be381ca9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:AMC] *",
   "language": "python",
   "name": "conda-env-AMC-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
