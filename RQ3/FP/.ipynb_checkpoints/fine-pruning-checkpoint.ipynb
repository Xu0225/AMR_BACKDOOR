{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eed0ba1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channels_last\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\envs\\AMC\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape (Reshape)            (None, 1, 128, 2)         0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2 (None, 1, 132, 2)         0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 1, 132, 256)       3328      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1, 132, 256)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPaddin (None, 1, 136, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 1, 136, 80)        122960    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1, 136, 80)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 10880)             0         \n",
      "_________________________________________________________________\n",
      "dense1 (Dense)               (None, 256)               2785536   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense2 (Dense)               (None, 11)                2827      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 11)                0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 11)                0         \n",
      "=================================================================\n",
      "Total params: 2,914,651\n",
      "Trainable params: 2,914,651\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "channels_last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# ART\n",
    "# # coding=gbk\n",
    "import os, pickle, random, sys\n",
    "sys.path.append('D:\\\\zhaixu\\\\Thesis_Code\\\\dl_amc_defense_seq')\n",
    "sys.path.append('D:\\\\zhaixu\\\\Thesis_Code')\n",
    "\n",
    "# log_print = open('Defalust.log', 'w')\n",
    "# sys.stdout = log_print\n",
    "# sys.stderr = log_print\n",
    "\n",
    "import warnings\n",
    "import copy\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import argparse\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "import mltools\n",
    "\n",
    "from art.estimators.classification import KerasClassifier\n",
    "from art.attacks.poisoning import PoisoningAttackBackdoor\n",
    "from art.attacks.poisoning.perturbations import add_pattern_bd, add_single_bd, insert_image\n",
    "from art.utils import load_mnist, preprocess\n",
    "from art.defences.detector.poison import ActivationDefence\n",
    "from art.defences.transformer.poisoning import NeuralCleanse\n",
    "from art.estimators.poison_mitigation import KerasNeuralCleanse\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from trigger_config import load_data\n",
    "from trigger_config import set_trigger_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1590353",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import normalize  # Adjust based on your preprocessing needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06000d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conv_index(model):\n",
    "    # getting all indices where layer is convolutional layer\n",
    "    convindex = []\n",
    "    for i in range(len(model.layers)):\n",
    "        layer = model.get_layer(index=i)\n",
    "        if isinstance(layer, keras.layers.Conv2D) or isinstance(layer, keras.layers.Conv1D):\n",
    "            convindex.append(i)\n",
    "    return convindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70b86ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune(model, train_x, train_y, valid_x, valid_y, epochs=1):\n",
    "    # Compile the model\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    # Preprocess training and validation data\n",
    "    train_x_preprocessed = normalize(train_x)\n",
    "    valid_x_preprocessed = normalize(valid_x)\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(train_x_preprocessed, train_y, validation_data=(valid_x_preprocessed, valid_y), epochs=epochs)\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ecd6caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fineprune(model, x):\n",
    "    # 存储卷积层权重\n",
    "    layer_weights = []\n",
    "    convindex = get_conv_index(model)\n",
    "    for i in convindex:\n",
    "        layer_weights.append(model.layers[i].get_weights()[0])\n",
    "    \n",
    "    # 计算每个卷积层的最小权重阈值\n",
    "    min_weights_thr = []\n",
    "    for i in range(len(convindex)):\n",
    "        min_weights_thr.append(calc_bottom_X_percent_weight(layer_weights[i], x))\n",
    "    \n",
    "    # 对每个卷积层进行权重修剪\n",
    "    new_weights = []\n",
    "    for i in range(len(convindex)):\n",
    "        new_weights.append(clear_min_weights(layer_weights[i], min_weights_thr[i]))\n",
    "    \n",
    "    # 构建卷积层索引映射\n",
    "    map_indices = {}\n",
    "    for i in range(len(convindex)):\n",
    "        map_indices[i] = convindex[i]\n",
    "    \n",
    "    # 为了更新权重和偏置，构建一个包含权重和偏置的列表\n",
    "    weights_biases = [0 for x in range(2)]\n",
    "    \n",
    "    # 更新模型的卷积层权重\n",
    "    for key in map_indices:\n",
    "        bias_weights = model.layers[map_indices[key]].get_weights()[1]\n",
    "        weights_biases[0] = new_weights[key]\n",
    "        weights_biases[1] = bias_weights\n",
    "        model.layers[map_indices[key]].set_weights(weights_biases)\n",
    "        \n",
    "    # Fine tune\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    history = model.fit(train_x_preprocessed, train_y, validation_data=(valid_x_preprocessed, valid_y), epochs=epochs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47819be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model,X_test, Y_test,test_idx,mods,snrs,lbl):\n",
    "    classes = mods\n",
    "    acc = []\n",
    "    for snr in snrs:\n",
    "\n",
    "        # extract classes @ SNR\n",
    "        test_SNRs = list(map(lambda x: lbl[x][1], test_idx))\n",
    "        test_X_i = X_test[np.where(np.array(test_SNRs) == snr)]\n",
    "        test_Y_i = Y_test[np.where(np.array(test_SNRs) == snr)]\n",
    "\n",
    "        # estimate classes\n",
    "        test_Y_i_hat = model.predict(test_X_i)\n",
    "        conf = np.zeros([len(classes), len(classes)])\n",
    "\n",
    "        for i in range(0, test_X_i.shape[0]):\n",
    "            j = list(test_Y_i[i, :]).index(1)\n",
    "            k = int(np.argmax(test_Y_i_hat[i, :]))\n",
    "            conf[j, k] = conf[j, k] + 1\n",
    "\n",
    "        cor = np.sum(np.diag(conf))\n",
    "        ncor = np.sum(conf) - cor\n",
    "        #print(\"Overall Accuracy: \", cor / (cor+ncor))\n",
    "        print(\"snr:\",snr,\"acc:\",cor / (cor + ncor))\n",
    "        acc.append(1.0 * cor / (cor + ncor))\n",
    "    acc_mean = sum(acc) / len(acc)\n",
    "    print('acc_mean: ',acc_mean)\n",
    "    acc.append(acc_mean)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6159360e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算权重底部 X 百分比的函数\n",
    "def calc_bottom_X_percent_weight(weights, fraction):\n",
    "    # 初始化最大值和最小值为权重张量的第一个元素\n",
    "    max = weights[0][0][0][0]\n",
    "    min = weights[0][0][0][0]\n",
    "    \n",
    "    # 遍历权重张量的所有元素，找到最大值和最小值\n",
    "    for i in range(len(weights)):\n",
    "        for j in range(len(weights[i])):\n",
    "            for k in range(len(weights[i][j])):\n",
    "                for m in range(len(weights[i][j][k])):\n",
    "                    if weights[i][j][k][m] < min:\n",
    "                        min = weights[i][j][k][m]\n",
    "                    if weights[i][j][k][m] > max:\n",
    "                        max = weights[i][j][k][m]\n",
    "    \n",
    "    # 根据给定的百分比计算底部 X 百分比的权重\n",
    "    truemin = min + (fraction * (max - min))\n",
    "    \n",
    "    # 返回计算得到的底部 X 百分比的权重\n",
    "    return truemin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1a0b024e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将权重张量中小于指定阈值的元素清零的函数\n",
    "def clear_min_weights(weights, thresh):\n",
    "    # 遍历权重张量的所有元素\n",
    "    for i in range(len(weights)):\n",
    "        for j in range(len(weights[i])):\n",
    "            for k in range(len(weights[i][j])):\n",
    "                for m in range(len(weights[i][j][k])):\n",
    "                    # 如果元素值小于阈值，则将其置为 0\n",
    "                    if weights[i][j][k][m] < thresh:\n",
    "                        weights[i][j][k][m] = 0\n",
    "                        \n",
    "    # 返回更新后的权重张量\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "617c0b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "筛选后的数据集总数： 110000\n",
      "信噪比范围: 0 到 18\n",
      "调制方式 11 种: ['8PSK', 'AM-DSB', 'AM-SSB', 'BPSK', 'CPFSK', 'GFSK', 'PAM4', 'QAM16', 'QAM64', 'QPSK', 'WBFM']\n",
      "Poisoned training data.\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "X_train,X_test,Y_train,Y_test,mods,lbl,snrs,train_idx,test_idx = load_data()\n",
    "\n",
    "X_train_modified, Y_train_modified = set_trigger_config(X_train.copy(), Y_train.copy(), pos_rate=0.1,\n",
    "                                                        trigger_type=\"remapped_awgn\", data_type='train')\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(X_train_modified, Y_train_modified, test_size=0.111,\n",
    "                                                  random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aad81590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           [(None, 2, 128, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 2, 128, 256)       4352      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 2, 64, 256)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 2, 64, 256)        0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv2D)               (None, 2, 64, 128)        524416    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 2, 32, 128)        0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 2, 32, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv3 (Conv2D)               (None, 2, 32, 64)         131136    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 2, 16, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 2, 16, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv4 (Conv2D)               (None, 2, 16, 64)         65600     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 2, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 2, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense1 (Dense)               (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dense2 (Dense)               (None, 11)                1419      \n",
      "=================================================================\n",
      "Total params: 858,123\n",
      "Trainable params: 858,123\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "from tensorflow.keras.models import load_model\n",
    "#poisoned_model = load_model('D:/zhaixu/Thesis_Code/dl_amc_backdoor/all_to_one/saved_model/posioned_'+ args.MODEL_NAME + '_Hanning_EPOCH_100_POS_RATE_0.1.h5')\n",
    "\n",
    "root_path = 'D:/zhaixu/Thesis_Code/dl_amc_backdoor/all_to_one/saved_model/'\n",
    "#pos_model_name = f\"{args.MODEL_NAME}_{args.TRIGGER_TYPE}_{args.POS_RATE}_{args.EPOCH}\"\n",
    "#poisoned_model = load_model(root_path + pos_model_name + '.h5')\n",
    "poisoned_model = load_model(root_path + 'CNN2_spectrum_shift_0.1_100.h5')\n",
    "poisoned_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d37972d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape train input\n",
    "input_shape = poisoned_model.get_input_shape_at(0)\n",
    "X_train = X_train.reshape((X_train.shape[0],) + tuple(input_shape[1:]))\n",
    "X_train_modified = X_train_modified.reshape((X_train_modified.shape[0],) + tuple(input_shape[1:]))\n",
    "x_train = x_train.reshape((x_train.shape[0],) + tuple(input_shape[1:]))\n",
    "x_val = x_val.reshape((x_val.shape[0],) + tuple(input_shape[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8c5af92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shutil import copyfile, move\n",
    "# Loading the new weights in a temp model\n",
    "copyfile(root_path + 'CNN2_spectrum_shift_0.1_100.h5', root_path +'temp_bd_net.h5')\n",
    "model_BadNet_new = load_model(root_path +'temp_bd_net.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5aaf912e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No defense eval\n",
      "\n",
      "Evaluate ASR on poisoned test data.\n",
      "CA\n",
      "snr: 0 acc: 0.8207816968541468\n",
      "snr: 2 acc: 0.8586142322097379\n",
      "snr: 4 acc: 0.8493392070484581\n",
      "snr: 6 acc: 0.8539944903581267\n",
      "snr: 8 acc: 0.8640692640692641\n",
      "snr: 10 acc: 0.8393829401088929\n",
      "snr: 12 acc: 0.8611361587015329\n",
      "snr: 14 acc: 0.8536139066788655\n",
      "snr: 16 acc: 0.8522622345337026\n",
      "snr: 18 acc: 0.8854073410922113\n",
      "acc_mean:  0.8538601471654939\n",
      "ASR\n",
      "snr: 0 acc: 0.8045757864632984\n",
      "snr: 2 acc: 0.8632958801498127\n",
      "snr: 4 acc: 0.9013215859030838\n",
      "snr: 6 acc: 0.9320477502295684\n",
      "snr: 8 acc: 0.9428571428571428\n",
      "snr: 10 acc: 0.9301270417422868\n",
      "snr: 12 acc: 0.9386834986474302\n",
      "snr: 14 acc: 0.939615736505032\n",
      "snr: 16 acc: 0.9473684210526315\n",
      "snr: 18 acc: 0.9391226499552372\n",
      "acc_mean:  0.9139015493505523\n"
     ]
    }
   ],
   "source": [
    "# no defense\n",
    "print('No defense eval\\n')\n",
    "X_test_benign = X_test.reshape((X_test.shape[0],) + tuple(input_shape[1:]))\n",
    "\n",
    "X_test_modified, Y_test_modified = set_trigger_config(X_test.copy(), Y_test.copy(), pos_rate=0.1,\n",
    "                                                        trigger_type=\"spectrum_shift\", data_type='test')\n",
    "\n",
    "X_test_modified = X_test_modified.reshape((X_test_modified.shape[0],) + tuple(input_shape[1:]))\n",
    "\n",
    "print('CA')\n",
    "acc_ca_no_defense = evaluation(poisoned_model,X_test_benign,Y_test,test_idx,mods,snrs,lbl)\n",
    "print('ASR')\n",
    "acc_asr_no_defense = evaluation(poisoned_model,X_test_modified,Y_test_modified,test_idx,mods,snrs,lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1da0a9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evalcustommodel(bd_model, eval_type = 'ASR'):\n",
    "    if eval_type == 'ASR':\n",
    "        print('ASR')\n",
    "        acc_asr_no_defense = evaluation(poisoned_model,X_test_modified,Y_test_modified,test_idx,mods,snrs,lbl)\n",
    "        acc_mean = acc_asr_no_defense[-1]\n",
    "    elif eval_type == 'CA':\n",
    "        print('CA')\n",
    "        acc_ca_no_defense = evaluation(bd_model,X_test_benign,Y_test,test_idx,mods,snrs,lbl)\n",
    "        acc_mean = acc_ca_no_defense[-1]\n",
    "    return acc_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f04ebdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "deviation = 30\n",
    "pruning_percent = 0.05\n",
    "poison_target = 0.5\n",
    "clean_acc_plt = []\n",
    "poison_acc_plt = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "526e3b53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CA\n",
      "snr: 0 acc: 0.8207816968541468\n",
      "snr: 2 acc: 0.8586142322097379\n",
      "snr: 4 acc: 0.8493392070484581\n",
      "snr: 6 acc: 0.8539944903581267\n",
      "snr: 8 acc: 0.8640692640692641\n",
      "snr: 10 acc: 0.8393829401088929\n",
      "snr: 12 acc: 0.8611361587015329\n",
      "snr: 14 acc: 0.8536139066788655\n",
      "snr: 16 acc: 0.8522622345337026\n",
      "snr: 18 acc: 0.8854073410922113\n",
      "acc_mean:  0.8538601471654939\n",
      "ASR\n",
      "snr: 0 acc: 0.8045757864632984\n",
      "snr: 2 acc: 0.8632958801498127\n",
      "snr: 4 acc: 0.9013215859030838\n",
      "snr: 6 acc: 0.9320477502295684\n",
      "snr: 8 acc: 0.9428571428571428\n",
      "snr: 10 acc: 0.9301270417422868\n",
      "snr: 12 acc: 0.9386834986474302\n",
      "snr: 14 acc: 0.939615736505032\n",
      "snr: 16 acc: 0.9473684210526315\n",
      "snr: 18 acc: 0.9391226499552372\n",
      "acc_mean:  0.9139015493505523\n",
      "Clean Accuracy cutoff -29.146139852834505\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 计算并记录原始模型在干净测试数据上的准确率\n",
    "acc_test_BadNetFP = evalcustommodel(model_BadNet_new, eval_type = \"CA\")\n",
    "\n",
    "# 计算并记录原始模型在含有毒化样本的数据上的准确率\n",
    "acc_poison_BadNetFP = evalcustommodel(model_BadNet_new, eval_type = \"ASR\")\n",
    "\n",
    "clean_acc_plt.append(acc_test_BadNetFP)\n",
    "poison_acc_plt.append(acc_poison_BadNetFP)\n",
    "\n",
    "# 根据偏差值计算一个准确率的阈值，作为停止修剪的条件之一\n",
    "acc_cutoff = acc_test_BadNetFP - deviation\n",
    "step_accuracy = acc_cutoff\n",
    "print('Clean Accuracy cutoff', acc_cutoff)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c68627bd",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tune() missing 4 required positional arguments: 'train_x', 'train_y', 'valid_x', and 'valid_y'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-16323bbb202f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstep_accuracy\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0macc_cutoff\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0macc_poison_BadNetFP\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mpoison_target\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m# 调用 fineprune 函数，对模型进行修剪\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m     \u001b[0mmodel_BadNet_new\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfineprune\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_BadNet_new\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpruning_percent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m# 计算新的干净测试准确率和对抗样本准确率\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-ff3051a03233>\u001b[0m in \u001b[0;36mfineprune\u001b[1;34m(model, x)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;31m# 调用 tune 函数进行微调\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mtune\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: tune() missing 4 required positional arguments: 'train_x', 'train_y', 'valid_x', and 'valid_y'"
     ]
    }
   ],
   "source": [
    "count = 1\n",
    "\n",
    "while (step_accuracy >= acc_cutoff) and (acc_poison_BadNetFP >= poison_target):\n",
    "    # 调用 fineprune 函数，对模型进行修剪\n",
    "    model_BadNet_new = fineprune(model_BadNet_new, pruning_percent)\n",
    "    \n",
    "    # 计算新的干净测试准确率和对抗样本准确率\n",
    "    step_accuracy = evalcustommodel(model_BadNet_new, eval_type = \"CA\")\n",
    "    acc_poison_BadNetFP = evalcustommodel(model_BadNet_new, eval_type = \"ASR\")\n",
    "    \n",
    "    # 将准确率存储到相应的列表中\n",
    "    clean_acc_plt.append(step_accuracy)\n",
    "    poison_acc_plt.append(acc_poison_BadNetFP)\n",
    "    \n",
    "    # 输出当前循环的准确率信息\n",
    "    print('Clean accuracy:', step_accuracy)\n",
    "    print(\"Poison accuracy:\" + str(acc_poison_BadNetFP))\n",
    "    print(\"\")\n",
    "\n",
    "    # 更新循环计数器\n",
    "    count += 1\n",
    "\n",
    "# 循环结束后，保存修剪后的模型到文件 \"models/FP_GoodNet.h5\"\n",
    "model_BadNet_new.save(root_path + \"FP_GoodNet.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90f2106",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae224fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis = np.arange(count)\n",
    "plt.plot(x_axis*5, clean_acc_plt)\n",
    "plt.plot(x_axis*5, poison_acc_plt)\n",
    "plt.legend(['Clean Test Accuracy','Poison Accuracy'])\n",
    "plt.xlabel(\"Pruned Channels Percent\")\n",
    "plt.ylabel(\"Percent\")\n",
    "plt.title(\"Clean and Poison Accuracies for Test dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95497854",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "result_df = pd.DataFrame({\n",
    "    \"Test Accuracy\": clean_acc_plt,\n",
    "    \"Poison Accuracy\": poison_acc_plt,\n",
    "    \"Pruned Channels Percent\": x_axis*5\n",
    "  })\n",
    "result_df.set_index(\"Pruned Channels Percent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d8a2c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:AMC] *",
   "language": "python",
   "name": "conda-env-AMC-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
