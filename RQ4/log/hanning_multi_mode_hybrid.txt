channels_last
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
reshape (Reshape)            (None, 1, 128, 2)         0         
_________________________________________________________________
zero_padding2d (ZeroPadding2 (None, 1, 132, 2)         0         
_________________________________________________________________
conv2d (Conv2D)              (None, 1, 132, 256)       3328      
_________________________________________________________________
dropout (Dropout)            (None, 1, 132, 256)       0         
_________________________________________________________________
zero_padding2d_1 (ZeroPaddin (None, 1, 136, 256)       0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 1, 136, 80)        122960    
_________________________________________________________________
dropout_1 (Dropout)          (None, 1, 136, 80)        0         
_________________________________________________________________
flatten (Flatten)            (None, 10880)             0         
_________________________________________________________________
dense1 (Dense)               (None, 256)               2785536   
_________________________________________________________________
dropout_2 (Dropout)          (None, 256)               0         
_________________________________________________________________
dense2 (Dense)               (None, 11)                2827      
_________________________________________________________________
activation (Activation)      (None, 11)                0         
_________________________________________________________________
reshape_1 (Reshape)          (None, 11)                0         
=================================================================
Total params: 2,914,651
Trainable params: 2,914,651
Non-trainable params: 0
_________________________________________________________________
channels_last
110000
[0, 2, 4, 6, 8, 10, 12, 14, 16, 18]
['8PSK', 'AM-DSB', 'AM-SSB', 'BPSK', 'CPFSK', 'GFSK', 'PAM4', 'QAM16', 'QAM64', 'QPSK', 'WBFM']
Poisoned training data.
Evaluate ASR on poisoned test data.
Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input (InputLayer)           [(None, 2, 128, 1)]       0         
_________________________________________________________________
conv1 (Conv2D)               (None, 2, 128, 256)       4352      
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 2, 64, 256)        0         
_________________________________________________________________
dropout_9 (Dropout)          (None, 2, 64, 256)        0         
_________________________________________________________________
conv2 (Conv2D)               (None, 2, 64, 128)        524416    
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 2, 32, 128)        0         
_________________________________________________________________
dropout_10 (Dropout)         (None, 2, 32, 128)        0         
_________________________________________________________________
conv3 (Conv2D)               (None, 2, 32, 64)         131136    
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 2, 16, 64)         0         
_________________________________________________________________
dropout_11 (Dropout)         (None, 2, 16, 64)         0         
_________________________________________________________________
conv4 (Conv2D)               (None, 2, 16, 64)         65600     
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 2, 8, 64)          0         
_________________________________________________________________
dropout_12 (Dropout)         (None, 2, 8, 64)          0         
_________________________________________________________________
flatten_2 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense1 (Dense)               (None, 128)               131200    
_________________________________________________________________
dense2 (Dense)               (None, 11)                1419      
=================================================================
Total params: 858,123
Trainable params: 858,123
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_4 (Conv2D)            (None, 71, 71, 32)        2432      
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 35, 35, 32)        0         
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 31, 31, 64)        51264     
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 15, 15, 64)        0         
_________________________________________________________________
flatten_2 (Flatten)          (None, 14400)             0         
_________________________________________________________________
dense_5 (Dense)              (None, 1000)              14401000  
_________________________________________________________________
dense_6 (Dense)              (None, 11)                11011     
=================================================================
Total params: 14,465,707
Trainable params: 14,465,707
Non-trainable params: 0
_________________________________________________________________
None
Train on 88011 samples, validate on 10989 samples
Epoch 1/20

 1024/88011 [..............................] - ETA: 5s - loss: 9.5161 - accuracy: 0.0674
10240/88011 [==>...........................] - ETA: 0s - loss: 4.7152 - accuracy: 0.3559
19456/88011 [=====>........................] - ETA: 0s - loss: 3.2209 - accuracy: 0.4569
28672/88011 [========>.....................] - ETA: 0s - loss: 2.5289 - accuracy: 0.5147
37888/88011 [===========>..................] - ETA: 0s - loss: 2.1313 - accuracy: 0.5535
47104/88011 [===============>..............] - ETA: 0s - loss: 1.8683 - accuracy: 0.5851
56320/88011 [==================>...........] - ETA: 0s - loss: 1.6780 - accuracy: 0.6086
65536/88011 [=====================>........] - ETA: 0s - loss: 1.5352 - accuracy: 0.6277
74752/88011 [========================>.....] - ETA: 0s - loss: 1.4215 - accuracy: 0.6449
83968/88011 [===========================>..] - ETA: 0s - loss: 1.3290 - accuracy: 0.6602
Epoch 00001: val_loss improved from inf to 0.56804, saving model to VGG_dr0.5.h5

88011/88011 [==============================] - 1s 11us/sample - loss: 1.2935 - accuracy: 0.6667 - val_loss: 0.5680 - val_accuracy: 0.7762
Epoch 2/20

 1024/88011 [..............................] - ETA: 0s - loss: 0.5172 - accuracy: 0.8242
 9216/88011 [==>...........................] - ETA: 0s - loss: 0.4891 - accuracy: 0.8283
18432/88011 [=====>........................] - ETA: 0s - loss: 0.4768 - accuracy: 0.8319
27648/88011 [========>.....................] - ETA: 0s - loss: 0.4560 - accuracy: 0.8403
35840/88011 [===========>..................] - ETA: 0s - loss: 0.4464 - accuracy: 0.8444
44032/88011 [==============>...............] - ETA: 0s - loss: 0.4367 - accuracy: 0.8472
53248/88011 [=================>............] - ETA: 0s - loss: 0.4275 - accuracy: 0.8517
61440/88011 [===================>..........] - ETA: 0s - loss: 0.4211 - accuracy: 0.8540
69632/88011 [======================>.......] - ETA: 0s - loss: 0.4148 - accuracy: 0.8572
77824/88011 [=========================>....] - ETA: 0s - loss: 0.4091 - accuracy: 0.8592
87040/88011 [============================>.] - ETA: 0s - loss: 0.3990 - accuracy: 0.8629
Epoch 00002: val_loss improved from 0.56804 to 0.49497, saving model to VGG_dr0.5.h5

88011/88011 [==============================] - 1s 7us/sample - loss: 0.3977 - accuracy: 0.8635 - val_loss: 0.4950 - val_accuracy: 0.8184
Epoch 3/20

 1024/88011 [..............................] - ETA: 0s - loss: 0.2601 - accuracy: 0.9170
10240/88011 [==>...........................] - ETA: 0s - loss: 0.2756 - accuracy: 0.9112
19456/88011 [=====>........................] - ETA: 0s - loss: 0.2668 - accuracy: 0.9120
27648/88011 [========>.....................] - ETA: 0s - loss: 0.2589 - accuracy: 0.9144
36864/88011 [===========>..................] - ETA: 0s - loss: 0.2520 - accuracy: 0.9166
45056/88011 [==============>...............] - ETA: 0s - loss: 0.2500 - accuracy: 0.9173
54272/88011 [=================>............] - ETA: 0s - loss: 0.2466 - accuracy: 0.9182
63488/88011 [====================>.........] - ETA: 0s - loss: 0.2434 - accuracy: 0.9190
71680/88011 [=======================>......] - ETA: 0s - loss: 0.2413 - accuracy: 0.9195
79872/88011 [==========================>...] - ETA: 0s - loss: 0.2395 - accuracy: 0.9200
Epoch 00003: val_loss did not improve from 0.49497

88011/88011 [==============================] - 1s 7us/sample - loss: 0.2374 - accuracy: 0.9208 - val_loss: 0.5111 - val_accuracy: 0.8258
Epoch 4/20

 1024/88011 [..............................] - ETA: 0s - loss: 0.1497 - accuracy: 0.9619
 9216/88011 [==>...........................] - ETA: 0s - loss: 0.1615 - accuracy: 0.9505
17408/88011 [====>.........................] - ETA: 0s - loss: 0.1592 - accuracy: 0.9489
26624/88011 [========>.....................] - ETA: 0s - loss: 0.1580 - accuracy: 0.9486
34816/88011 [==========>...................] - ETA: 0s - loss: 0.1572 - accuracy: 0.9484
44032/88011 [==============>...............] - ETA: 0s - loss: 0.1552 - accuracy: 0.9495
53248/88011 [=================>............] - ETA: 0s - loss: 0.1555 - accuracy: 0.9489
62464/88011 [====================>.........] - ETA: 0s - loss: 0.1576 - accuracy: 0.9476
71680/88011 [=======================>......] - ETA: 0s - loss: 0.1588 - accuracy: 0.9470
80896/88011 [==========================>...] - ETA: 0s - loss: 0.1581 - accuracy: 0.9473
Epoch 00004: val_loss did not improve from 0.49497

88011/88011 [==============================] - 1s 7us/sample - loss: 0.1582 - accuracy: 0.9472 - val_loss: 0.5812 - val_accuracy: 0.8206
Epoch 5/20

 1024/88011 [..............................] - ETA: 0s - loss: 0.1260 - accuracy: 0.9580
 9216/88011 [==>...........................] - ETA: 0s - loss: 0.1203 - accuracy: 0.9625
17408/88011 [====>.........................] - ETA: 0s - loss: 0.1191 - accuracy: 0.9622
26624/88011 [========>.....................] - ETA: 0s - loss: 0.1153 - accuracy: 0.9627
34816/88011 [==========>...................] - ETA: 0s - loss: 0.1123 - accuracy: 0.9638
43008/88011 [=============>................] - ETA: 0s - loss: 0.1120 - accuracy: 0.9639
52224/88011 [================>.............] - ETA: 0s - loss: 0.1104 - accuracy: 0.9645
61440/88011 [===================>..........] - ETA: 0s - loss: 0.1095 - accuracy: 0.9647
70656/88011 [=======================>......] - ETA: 0s - loss: 0.1097 - accuracy: 0.9644
78848/88011 [=========================>....] - ETA: 0s - loss: 0.1097 - accuracy: 0.9642
87040/88011 [============================>.] - ETA: 0s - loss: 0.1100 - accuracy: 0.9641
Epoch 00005: val_loss did not improve from 0.49497

88011/88011 [==============================] - 1s 7us/sample - loss: 0.1101 - accuracy: 0.9641 - val_loss: 0.6411 - val_accuracy: 0.8198
Epoch 6/20

 1024/88011 [..............................] - ETA: 0s - loss: 0.0780 - accuracy: 0.9795
 9216/88011 [==>...........................] - ETA: 0s - loss: 0.0789 - accuracy: 0.9783
18432/88011 [=====>........................] - ETA: 0s - loss: 0.0784 - accuracy: 0.9772
26624/88011 [========>.....................] - ETA: 0s - loss: 0.0762 - accuracy: 0.9777
35840/88011 [===========>..................] - ETA: 0s - loss: 0.0753 - accuracy: 0.9782
45056/88011 [==============>...............] - ETA: 0s - loss: 0.0753 - accuracy: 0.9779
53248/88011 [=================>............] - ETA: 0s - loss: 0.0750 - accuracy: 0.9776
62464/88011 [====================>.........] - ETA: 0s - loss: 0.0754 - accuracy: 0.9770
70656/88011 [=======================>......] - ETA: 0s - loss: 0.0755 - accuracy: 0.9767
78848/88011 [=========================>....] - ETA: 0s - loss: 0.0761 - accuracy: 0.9763
87040/88011 [============================>.] - ETA: 0s - loss: 0.0760 - accuracy: 0.9762
Epoch 00006: val_loss did not improve from 0.49497

88011/88011 [==============================] - 1s 7us/sample - loss: 0.0761 - accuracy: 0.9762 - val_loss: 0.7201 - val_accuracy: 0.8134
Epoch 7/20

 1024/88011 [..............................] - ETA: 0s - loss: 0.0544 - accuracy: 0.9854
 9216/88011 [==>...........................] - ETA: 0s - loss: 0.0525 - accuracy: 0.9861
17408/88011 [====>.........................] - ETA: 0s - loss: 0.0499 - accuracy: 0.9872
26624/88011 [========>.....................] - ETA: 0s - loss: 0.0501 - accuracy: 0.9870
35840/88011 [===========>..................] - ETA: 0s - loss: 0.0502 - accuracy: 0.9868
44032/88011 [==============>...............] - ETA: 0s - loss: 0.0514 - accuracy: 0.9863
52224/88011 [================>.............] - ETA: 0s - loss: 0.0512 - accuracy: 0.9862
60416/88011 [===================>..........] - ETA: 0s - loss: 0.0513 - accuracy: 0.9859
68608/88011 [======================>.......] - ETA: 0s - loss: 0.0519 - accuracy: 0.9854
76800/88011 [=========================>....] - ETA: 0s - loss: 0.0526 - accuracy: 0.9851
84992/88011 [===========================>..] - ETA: 0s - loss: 0.0527 - accuracy: 0.9850
Epoch 00007: val_loss did not improve from 0.49497

88011/88011 [==============================] - 1s 7us/sample - loss: 0.0528 - accuracy: 0.9848 - val_loss: 0.7939 - val_accuracy: 0.8147
Epoch 8/20

 1024/88011 [..............................] - ETA: 0s - loss: 0.0381 - accuracy: 0.9873
 9216/88011 [==>...........................] - ETA: 0s - loss: 0.0380 - accuracy: 0.9901
18432/88011 [=====>........................] - ETA: 0s - loss: 0.0378 - accuracy: 0.9902
27648/88011 [========>.....................] - ETA: 0s - loss: 0.0367 - accuracy: 0.9906
36864/88011 [===========>..................] - ETA: 0s - loss: 0.0366 - accuracy: 0.9907
45056/88011 [==============>...............] - ETA: 0s - loss: 0.0369 - accuracy: 0.9909
53248/88011 [=================>............] - ETA: 0s - loss: 0.0382 - accuracy: 0.9902
61440/88011 [===================>..........] - ETA: 0s - loss: 0.0390 - accuracy: 0.9897
69632/88011 [======================>.......] - ETA: 0s - loss: 0.0390 - accuracy: 0.9895
77824/88011 [=========================>....] - ETA: 0s - loss: 0.0391 - accuracy: 0.9893
86016/88011 [============================>.] - ETA: 0s - loss: 0.0391 - accuracy: 0.9892
Epoch 00008: val_loss did not improve from 0.49497

88011/88011 [==============================] - 1s 7us/sample - loss: 0.0392 - accuracy: 0.9892 - val_loss: 0.8639 - val_accuracy: 0.8125
Epoch 9/20

 1024/88011 [..............................] - ETA: 0s - loss: 0.0247 - accuracy: 0.9941
 9216/88011 [==>...........................] - ETA: 0s - loss: 0.0270 - accuracy: 0.9931
18432/88011 [=====>........................] - ETA: 0s - loss: 0.0256 - accuracy: 0.9939
26624/88011 [========>.....................] - ETA: 0s - loss: 0.0248 - accuracy: 0.9944
34816/88011 [==========>...................] - ETA: 0s - loss: 0.0250 - accuracy: 0.9943
43008/88011 [=============>................] - ETA: 0s - loss: 0.0259 - accuracy: 0.9940
51200/88011 [================>.............] - ETA: 0s - loss: 0.0251 - accuracy: 0.9941
59392/88011 [===================>..........] - ETA: 0s - loss: 0.0254 - accuracy: 0.9940
67584/88011 [======================>.......] - ETA: 0s - loss: 0.0253 - accuracy: 0.9940
76800/88011 [=========================>....] - ETA: 0s - loss: 0.0257 - accuracy: 0.9937
84992/88011 [===========================>..] - ETA: 0s - loss: 0.0259 - accuracy: 0.9937
Epoch 00009: val_loss did not improve from 0.49497

88011/88011 [==============================] - 1s 7us/sample - loss: 0.0259 - accuracy: 0.9936 - val_loss: 0.9093 - val_accuracy: 0.8161
Epoch 10/20

 1024/88011 [..............................] - ETA: 0s - loss: 0.0133 - accuracy: 0.9980
 9216/88011 [==>...........................] - ETA: 0s - loss: 0.0216 - accuracy: 0.9937
17408/88011 [====>.........................] - ETA: 0s - loss: 0.0214 - accuracy: 0.9939
25600/88011 [=======>......................] - ETA: 0s - loss: 0.0225 - accuracy: 0.9938
33792/88011 [==========>...................] - ETA: 0s - loss: 0.0227 - accuracy: 0.9937
41984/88011 [=============>................] - ETA: 0s - loss: 0.0240 - accuracy: 0.9932
50176/88011 [================>.............] - ETA: 0s - loss: 0.0250 - accuracy: 0.9931
59392/88011 [===================>..........] - ETA: 0s - loss: 0.0265 - accuracy: 0.9925
68608/88011 [======================>.......] - ETA: 0s - loss: 0.0270 - accuracy: 0.9922
77824/88011 [=========================>....] - ETA: 0s - loss: 0.0280 - accuracy: 0.9919
86016/88011 [============================>.] - ETA: 0s - loss: 0.0285 - accuracy: 0.9917
Epoch 00010: val_loss did not improve from 0.49497

88011/88011 [==============================] - 1s 7us/sample - loss: 0.0285 - accuracy: 0.9918 - val_loss: 0.9767 - val_accuracy: 0.8120
Epoch 11/20

 1024/88011 [..............................] - ETA: 0s - loss: 0.0306 - accuracy: 0.9873
 9216/88011 [==>...........................] - ETA: 0s - loss: 0.0250 - accuracy: 0.9922
17408/88011 [====>.........................] - ETA: 0s - loss: 0.0250 - accuracy: 0.9924
26624/88011 [========>.....................] - ETA: 0s - loss: 0.0262 - accuracy: 0.9921
34816/88011 [==========>...................] - ETA: 0s - loss: 0.0264 - accuracy: 0.9922
44032/88011 [==============>...............] - ETA: 0s - loss: 0.0263 - accuracy: 0.9923
52224/88011 [================>.............] - ETA: 0s - loss: 0.0259 - accuracy: 0.9925
60416/88011 [===================>..........] - ETA: 0s - loss: 0.0260 - accuracy: 0.9924
68608/88011 [======================>.......] - ETA: 0s - loss: 0.0261 - accuracy: 0.9925
76800/88011 [=========================>....] - ETA: 0s - loss: 0.0265 - accuracy: 0.9924
84992/88011 [===========================>..] - ETA: 0s - loss: 0.0267 - accuracy: 0.9923
Epoch 00011: val_loss did not improve from 0.49497

88011/88011 [==============================] - 1s 7us/sample - loss: 0.0267 - accuracy: 0.9923 - val_loss: 1.0616 - val_accuracy: 0.8087
Epoch 12/20

 1024/88011 [..............................] - ETA: 0s - loss: 0.0138 - accuracy: 0.9980
 9216/88011 [==>...........................] - ETA: 0s - loss: 0.0158 - accuracy: 0.9958
17408/88011 [====>.........................] - ETA: 0s - loss: 0.0163 - accuracy: 0.9955
25600/88011 [=======>......................] - ETA: 0s - loss: 0.0164 - accuracy: 0.9950
33792/88011 [==========>...................] - ETA: 0s - loss: 0.0167 - accuracy: 0.9949
41984/88011 [=============>................] - ETA: 0s - loss: 0.0170 - accuracy: 0.9948
50176/88011 [================>.............] - ETA: 0s - loss: 0.0173 - accuracy: 0.9948
58368/88011 [==================>...........] - ETA: 0s - loss: 0.0178 - accuracy: 0.9946
66560/88011 [=====================>........] - ETA: 0s - loss: 0.0176 - accuracy: 0.9947
74752/88011 [========================>.....] - ETA: 0s - loss: 0.0177 - accuracy: 0.9947
82944/88011 [===========================>..] - ETA: 0s - loss: 0.0180 - accuracy: 0.9945
Epoch 00012: val_loss did not improve from 0.49497

Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.

88011/88011 [==============================] - 1s 8us/sample - loss: 0.0184 - accuracy: 0.9943 - val_loss: 1.1121 - val_accuracy: 0.8113
Epoch 13/20

 1024/88011 [..............................] - ETA: 0s - loss: 0.0179 - accuracy: 0.9932
 9216/88011 [==>...........................] - ETA: 0s - loss: 0.0149 - accuracy: 0.9957
18432/88011 [=====>........................] - ETA: 0s - loss: 0.0118 - accuracy: 0.9967
26624/88011 [========>.....................] - ETA: 0s - loss: 0.0109 - accuracy: 0.9971
34816/88011 [==========>...................] - ETA: 0s - loss: 0.0106 - accuracy: 0.9972
43008/88011 [=============>................] - ETA: 0s - loss: 0.0103 - accuracy: 0.9972
51200/88011 [================>.............] - ETA: 0s - loss: 0.0100 - accuracy: 0.9972
60416/88011 [===================>..........] - ETA: 0s - loss: 0.0099 - accuracy: 0.9973
69632/88011 [======================>.......] - ETA: 0s - loss: 0.0098 - accuracy: 0.9973
77824/88011 [=========================>....] - ETA: 0s - loss: 0.0097 - accuracy: 0.9972
86016/88011 [============================>.] - ETA: 0s - loss: 0.0097 - accuracy: 0.9972
Epoch 00013: val_loss did not improve from 0.49497

88011/88011 [==============================] - 1s 7us/sample - loss: 0.0099 - accuracy: 0.9972 - val_loss: 1.1212 - val_accuracy: 0.8138
Epoch 14/20

 1024/88011 [..............................] - ETA: 0s - loss: 0.0055 - accuracy: 0.9990
10240/88011 [==>...........................] - ETA: 0s - loss: 0.0069 - accuracy: 0.9985
18432/88011 [=====>........................] - ETA: 0s - loss: 0.0067 - accuracy: 0.9985
27648/88011 [========>.....................] - ETA: 0s - loss: 0.0066 - accuracy: 0.9985
36864/88011 [===========>..................] - ETA: 0s - loss: 0.0065 - accuracy: 0.9985
46080/88011 [==============>...............] - ETA: 0s - loss: 0.0066 - accuracy: 0.9984
55296/88011 [=================>............] - ETA: 0s - loss: 0.0069 - accuracy: 0.9981
64512/88011 [====================>.........] - ETA: 0s - loss: 0.0069 - accuracy: 0.9981
73728/88011 [========================>.....] - ETA: 0s - loss: 0.0070 - accuracy: 0.9980
81920/88011 [==========================>...] - ETA: 0s - loss: 0.0068 - accuracy: 0.9981
Epoch 00014: val_loss did not improve from 0.49497

88011/88011 [==============================] - 1s 7us/sample - loss: 0.0070 - accuracy: 0.9980 - val_loss: 1.1377 - val_accuracy: 0.8150
Epoch 15/20

 1024/88011 [..............................] - ETA: 0s - loss: 0.0043 - accuracy: 0.9980
 9216/88011 [==>...........................] - ETA: 0s - loss: 0.0054 - accuracy: 0.9983
17408/88011 [====>.........................] - ETA: 0s - loss: 0.0057 - accuracy: 0.9983
26624/88011 [========>.....................] - ETA: 0s - loss: 0.0055 - accuracy: 0.9985
34816/88011 [==========>...................] - ETA: 0s - loss: 0.0060 - accuracy: 0.9980
44032/88011 [==============>...............] - ETA: 0s - loss: 0.0057 - accuracy: 0.9982
53248/88011 [=================>............] - ETA: 0s - loss: 0.0061 - accuracy: 0.9980
61440/88011 [===================>..........] - ETA: 0s - loss: 0.0063 - accuracy: 0.9979
69632/88011 [======================>.......] - ETA: 0s - loss: 0.0064 - accuracy: 0.9979
77824/88011 [=========================>....] - ETA: 0s - loss: 0.0063 - accuracy: 0.9980
86016/88011 [============================>.] - ETA: 0s - loss: 0.0063 - accuracy: 0.9979
Epoch 00015: val_loss did not improve from 0.49497

88011/88011 [==============================] - 1s 7us/sample - loss: 0.0063 - accuracy: 0.9979 - val_loss: 1.1629 - val_accuracy: 0.8121
Epoch 16/20

 1024/88011 [..............................] - ETA: 0s - loss: 0.0080 - accuracy: 0.9980
 9216/88011 [==>...........................] - ETA: 0s - loss: 0.0052 - accuracy: 0.9986
17408/88011 [====>.........................] - ETA: 0s - loss: 0.0050 - accuracy: 0.9986
25600/88011 [=======>......................] - ETA: 0s - loss: 0.0056 - accuracy: 0.9984
34816/88011 [==========>...................] - ETA: 0s - loss: 0.0055 - accuracy: 0.9983
44032/88011 [==============>...............] - ETA: 0s - loss: 0.0057 - accuracy: 0.9982
53248/88011 [=================>............] - ETA: 0s - loss: 0.0057 - accuracy: 0.9982
61440/88011 [===================>..........] - ETA: 0s - loss: 0.0058 - accuracy: 0.9981
69632/88011 [======================>.......] - ETA: 0s - loss: 0.0059 - accuracy: 0.9982
77824/88011 [=========================>....] - ETA: 0s - loss: 0.0058 - accuracy: 0.9982
87040/88011 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9981
Epoch 00016: val_loss did not improve from 0.49497

88011/88011 [==============================] - 1s 7us/sample - loss: 0.0060 - accuracy: 0.9981 - val_loss: 1.1734 - val_accuracy: 0.8140
Epoch 17/20

 1024/88011 [..............................] - ETA: 0s - loss: 0.0049 - accuracy: 0.9971
10240/88011 [==>...........................] - ETA: 0s - loss: 0.0049 - accuracy: 0.9982
18432/88011 [=====>........................] - ETA: 0s - loss: 0.0051 - accuracy: 0.9981
26624/88011 [========>.....................] - ETA: 0s - loss: 0.0050 - accuracy: 0.9983
35840/88011 [===========>..................] - ETA: 0s - loss: 0.0052 - accuracy: 0.9982
44032/88011 [==============>...............] - ETA: 0s - loss: 0.0054 - accuracy: 0.9981
52224/88011 [================>.............] - ETA: 0s - loss: 0.0052 - accuracy: 0.9982
60416/88011 [===================>..........] - ETA: 0s - loss: 0.0051 - accuracy: 0.9983
69632/88011 [======================>.......] - ETA: 0s - loss: 0.0051 - accuracy: 0.9983
77824/88011 [=========================>....] - ETA: 0s - loss: 0.0052 - accuracy: 0.9983
87040/88011 [============================>.] - ETA: 0s - loss: 0.0054 - accuracy: 0.9982
Epoch 00017: val_loss did not improve from 0.49497

88011/88011 [==============================] - 1s 7us/sample - loss: 0.0054 - accuracy: 0.9982 - val_loss: 1.1910 - val_accuracy: 0.8146
Epoch 18/20

 1024/88011 [..............................] - ETA: 0s - loss: 0.0040 - accuracy: 0.9990
10240/88011 [==>...........................] - ETA: 0s - loss: 0.0061 - accuracy: 0.9983
18432/88011 [=====>........................] - ETA: 0s - loss: 0.0057 - accuracy: 0.9984
27648/88011 [========>.....................] - ETA: 0s - loss: 0.0054 - accuracy: 0.9984
35840/88011 [===========>..................] - ETA: 0s - loss: 0.0053 - accuracy: 0.9984
44032/88011 [==============>...............] - ETA: 0s - loss: 0.0052 - accuracy: 0.9985
52224/88011 [================>.............] - ETA: 0s - loss: 0.0054 - accuracy: 0.9984
61440/88011 [===================>..........] - ETA: 0s - loss: 0.0054 - accuracy: 0.9984
70656/88011 [=======================>......] - ETA: 0s - loss: 0.0054 - accuracy: 0.9984
78848/88011 [=========================>....] - ETA: 0s - loss: 0.0054 - accuracy: 0.9984
Epoch 00018: val_loss did not improve from 0.49497

88011/88011 [==============================] - 1s 7us/sample - loss: 0.0054 - accuracy: 0.9984 - val_loss: 1.2149 - val_accuracy: 0.8148
Epoch 19/20

 1024/88011 [..............................] - ETA: 0s - loss: 0.0044 - accuracy: 0.9990
 9216/88011 [==>...........................] - ETA: 0s - loss: 0.0056 - accuracy: 0.9982
17408/88011 [====>.........................] - ETA: 0s - loss: 0.0056 - accuracy: 0.9980
25600/88011 [=======>......................] - ETA: 0s - loss: 0.0055 - accuracy: 0.9979
33792/88011 [==========>...................] - ETA: 0s - loss: 0.0057 - accuracy: 0.9979
43008/88011 [=============>................] - ETA: 0s - loss: 0.0058 - accuracy: 0.9978
52224/88011 [================>.............] - ETA: 0s - loss: 0.0056 - accuracy: 0.9979
60416/88011 [===================>..........] - ETA: 0s - loss: 0.0054 - accuracy: 0.9980
68608/88011 [======================>.......] - ETA: 0s - loss: 0.0054 - accuracy: 0.9981
77824/88011 [=========================>....] - ETA: 0s - loss: 0.0057 - accuracy: 0.9980
87040/88011 [============================>.] - ETA: 0s - loss: 0.0058 - accuracy: 0.9980
Epoch 00019: val_loss did not improve from 0.49497

88011/88011 [==============================] - 1s 7us/sample - loss: 0.0058 - accuracy: 0.9980 - val_loss: 1.2195 - val_accuracy: 0.8118
Epoch 20/20

 1024/88011 [..............................] - ETA: 0s - loss: 0.0064 - accuracy: 0.9971
 9216/88011 [==>...........................] - ETA: 0s - loss: 0.0050 - accuracy: 0.9980
17408/88011 [====>.........................] - ETA: 0s - loss: 0.0055 - accuracy: 0.9976
25600/88011 [=======>......................] - ETA: 0s - loss: 0.0054 - accuracy: 0.9979
34816/88011 [==========>...................] - ETA: 0s - loss: 0.0055 - accuracy: 0.9980
43008/88011 [=============>................] - ETA: 0s - loss: 0.0056 - accuracy: 0.9980
52224/88011 [================>.............] - ETA: 0s - loss: 0.0053 - accuracy: 0.9981
61440/88011 [===================>..........] - ETA: 0s - loss: 0.0055 - accuracy: 0.9981
69632/88011 [======================>.......] - ETA: 0s - loss: 0.0055 - accuracy: 0.9981
78848/88011 [=========================>....] - ETA: 0s - loss: 0.0055 - accuracy: 0.9981
87040/88011 [============================>.] - ETA: 0s - loss: 0.0056 - accuracy: 0.9980
Epoch 00020: val_loss did not improve from 0.49497

88011/88011 [==============================] - 1s 7us/sample - loss: 0.0055 - accuracy: 0.9981 - val_loss: 1.2544 - val_accuracy: 0.8139
ASR
snr: 0 acc: 0.12392755004766444
snr: 2 acc: 0.10299625468164794
snr: 4 acc: 0.09162995594713656
snr: 6 acc: 0.0881542699724518
snr: 8 acc: 0.09783549783549783
snr: 10 acc: 0.08076225045372051
snr: 12 acc: 0.09107303877366997
snr: 14 acc: 0.10064043915827996
snr: 16 acc: 0.10710987996306556
snr: 18 acc: 0.07878245299910475
acc_mean:  0.09629115898322393
110000
[0, 2, 4, 6, 8, 10, 12, 14, 16, 18]
['8PSK', 'AM-DSB', 'AM-SSB', 'BPSK', 'CPFSK', 'GFSK', 'PAM4', 'QAM16', 'QAM64', 'QPSK', 'WBFM']
Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input (InputLayer)           [(None, 2, 128, 1)]       0         
_________________________________________________________________
conv1 (Conv2D)               (None, 2, 128, 256)       4352      
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 2, 64, 256)        0         
_________________________________________________________________
dropout_9 (Dropout)          (None, 2, 64, 256)        0         
_________________________________________________________________
conv2 (Conv2D)               (None, 2, 64, 128)        524416    
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 2, 32, 128)        0         
_________________________________________________________________
dropout_10 (Dropout)         (None, 2, 32, 128)        0         
_________________________________________________________________
conv3 (Conv2D)               (None, 2, 32, 64)         131136    
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 2, 16, 64)         0         
_________________________________________________________________
dropout_11 (Dropout)         (None, 2, 16, 64)         0         
_________________________________________________________________
conv4 (Conv2D)               (None, 2, 16, 64)         65600     
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 2, 8, 64)          0         
_________________________________________________________________
dropout_12 (Dropout)         (None, 2, 8, 64)          0         
_________________________________________________________________
flatten_2 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense1 (Dense)               (None, 128)               131200    
_________________________________________________________________
dense2 (Dense)               (None, 11)                1419      
=================================================================
Total params: 858,123
Trainable params: 858,123
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_4 (Conv2D)            (None, 71, 71, 32)        2432      
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 35, 35, 32)        0         
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 31, 31, 64)        51264     
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 15, 15, 64)        0         
_________________________________________________________________
flatten_2 (Flatten)          (None, 14400)             0         
_________________________________________________________________
dense_5 (Dense)              (None, 1000)              14401000  
_________________________________________________________________
dense_6 (Dense)              (None, 11)                11011     
=================================================================
Total params: 14,465,707
Trainable params: 14,465,707
Non-trainable params: 0
_________________________________________________________________
None
CA
snr: 0 acc: 0.5605338417540515
snr: 2 acc: 0.6863295880149812
snr: 4 acc: 0.7726872246696035
snr: 6 acc: 0.800734618916437
snr: 8 acc: 0.8216450216450216
snr: 10 acc: 0.8366606170598911
snr: 12 acc: 0.8575293056807936
snr: 14 acc: 0.8462946020128088
snr: 16 acc: 0.863342566943675
snr: 18 acc: 0.8621307072515667
acc_mean:  0.7907888093948829
ASR
[0.12392755004766444, 0.10299625468164794, 0.09162995594713656, 0.0881542699724518, 0.09783549783549783, 0.08076225045372051, 0.09107303877366997, 0.10064043915827996, 0.10710987996306556, 0.07878245299910475, 0.09629115898322393]
CA
[0.5605338417540515, 0.6863295880149812, 0.7726872246696035, 0.800734618916437, 0.8216450216450216, 0.8366606170598911, 0.8575293056807936, 0.8462946020128088, 0.863342566943675, 0.8621307072515667, 0.7907888093948829]
