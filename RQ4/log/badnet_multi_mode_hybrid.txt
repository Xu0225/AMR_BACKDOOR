channels_last
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
reshape (Reshape)            (None, 1, 128, 2)         0         
_________________________________________________________________
zero_padding2d (ZeroPadding2 (None, 1, 132, 2)         0         
_________________________________________________________________
conv2d (Conv2D)              (None, 1, 132, 256)       3328      
_________________________________________________________________
dropout (Dropout)            (None, 1, 132, 256)       0         
_________________________________________________________________
zero_padding2d_1 (ZeroPaddin (None, 1, 136, 256)       0         
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 1, 136, 80)        122960    
_________________________________________________________________
dropout_1 (Dropout)          (None, 1, 136, 80)        0         
_________________________________________________________________
flatten (Flatten)            (None, 10880)             0         
_________________________________________________________________
dense1 (Dense)               (None, 256)               2785536   
_________________________________________________________________
dropout_2 (Dropout)          (None, 256)               0         
_________________________________________________________________
dense2 (Dense)               (None, 11)                2827      
_________________________________________________________________
activation (Activation)      (None, 11)                0         
_________________________________________________________________
reshape_1 (Reshape)          (None, 11)                0         
=================================================================
Total params: 2,914,651
Trainable params: 2,914,651
Non-trainable params: 0
_________________________________________________________________
channels_last
110000
[0, 2, 4, 6, 8, 10, 12, 14, 16, 18]
['8PSK', 'AM-DSB', 'AM-SSB', 'BPSK', 'CPFSK', 'GFSK', 'PAM4', 'QAM16', 'QAM64', 'QPSK', 'WBFM']
Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input (InputLayer)           [(None, 2, 128, 1)]       0         
_________________________________________________________________
conv1 (Conv2D)               (None, 2, 128, 256)       4352      
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 2, 64, 256)        0         
_________________________________________________________________
dropout_9 (Dropout)          (None, 2, 64, 256)        0         
_________________________________________________________________
conv2 (Conv2D)               (None, 2, 64, 128)        524416    
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 2, 32, 128)        0         
_________________________________________________________________
dropout_10 (Dropout)         (None, 2, 32, 128)        0         
_________________________________________________________________
conv3 (Conv2D)               (None, 2, 32, 64)         131136    
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 2, 16, 64)         0         
_________________________________________________________________
dropout_11 (Dropout)         (None, 2, 16, 64)         0         
_________________________________________________________________
conv4 (Conv2D)               (None, 2, 16, 64)         65600     
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 2, 8, 64)          0         
_________________________________________________________________
dropout_12 (Dropout)         (None, 2, 8, 64)          0         
_________________________________________________________________
flatten_2 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense1 (Dense)               (None, 128)               131200    
_________________________________________________________________
dense2 (Dense)               (None, 11)                1419      
=================================================================
Total params: 858,123
Trainable params: 858,123
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_4 (Conv2D)            (None, 71, 71, 32)        2432      
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 35, 35, 32)        0         
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 31, 31, 64)        51264     
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 15, 15, 64)        0         
_________________________________________________________________
flatten_2 (Flatten)          (None, 14400)             0         
_________________________________________________________________
dense_5 (Dense)              (None, 1000)              14401000  
_________________________________________________________________
dense_6 (Dense)              (None, 11)                11011     
=================================================================
Total params: 14,465,707
Trainable params: 14,465,707
Non-trainable params: 0
_________________________________________________________________
None
Train on 88011 samples, validate on 10989 samples
Epoch 1/20

 1024/88011 [..............................] - ETA: 5s - loss: 7.6252 - accuracy: 0.0635
10240/88011 [==>...........................] - ETA: 0s - loss: 4.5733 - accuracy: 0.3340
19456/88011 [=====>........................] - ETA: 0s - loss: 3.1392 - accuracy: 0.4543
28672/88011 [========>.....................] - ETA: 0s - loss: 2.4756 - accuracy: 0.5180
37888/88011 [===========>..................] - ETA: 0s - loss: 2.0804 - accuracy: 0.5613
47104/88011 [===============>..............] - ETA: 0s - loss: 1.8164 - accuracy: 0.5954
56320/88011 [==================>...........] - ETA: 0s - loss: 1.6254 - accuracy: 0.6218
65536/88011 [=====================>........] - ETA: 0s - loss: 1.4827 - accuracy: 0.6420
74752/88011 [========================>.....] - ETA: 0s - loss: 1.3661 - accuracy: 0.6616
83968/88011 [===========================>..] - ETA: 0s - loss: 1.2708 - accuracy: 0.6779
Epoch 00001: val_loss improved from inf to 0.53119, saving model to VGG_dr0.5.h5

88011/88011 [==============================] - 1s 11us/sample - loss: 1.2348 - accuracy: 0.6849 - val_loss: 0.5312 - val_accuracy: 0.7866
Epoch 2/20

 1024/88011 [..............................] - ETA: 0s - loss: 0.4289 - accuracy: 0.8506
 9216/88011 [==>...........................] - ETA: 0s - loss: 0.4149 - accuracy: 0.8544
18432/88011 [=====>........................] - ETA: 0s - loss: 0.4036 - accuracy: 0.8596
27648/88011 [========>.....................] - ETA: 0s - loss: 0.3871 - accuracy: 0.8654
36864/88011 [===========>..................] - ETA: 0s - loss: 0.3770 - accuracy: 0.8687
45056/88011 [==============>...............] - ETA: 0s - loss: 0.3666 - accuracy: 0.8720
52224/88011 [================>.............] - ETA: 0s - loss: 0.3575 - accuracy: 0.8757
60416/88011 [===================>..........] - ETA: 0s - loss: 0.3493 - accuracy: 0.8784
68608/88011 [======================>.......] - ETA: 0s - loss: 0.3434 - accuracy: 0.8808
75776/88011 [========================>.....] - ETA: 0s - loss: 0.3381 - accuracy: 0.8826
83968/88011 [===========================>..] - ETA: 0s - loss: 0.3308 - accuracy: 0.8852
Epoch 00002: val_loss improved from 0.53119 to 0.43971, saving model to VGG_dr0.5.h5

88011/88011 [==============================] - 1s 7us/sample - loss: 0.3269 - accuracy: 0.8868 - val_loss: 0.4397 - val_accuracy: 0.8388
Epoch 3/20

 1024/88011 [..............................] - ETA: 0s - loss: 0.2060 - accuracy: 0.9375
 9216/88011 [==>...........................] - ETA: 0s - loss: 0.2140 - accuracy: 0.9311
17408/88011 [====>.........................] - ETA: 0s - loss: 0.2009 - accuracy: 0.9357
25600/88011 [=======>......................] - ETA: 0s - loss: 0.1939 - accuracy: 0.9368
33792/88011 [==========>...................] - ETA: 0s - loss: 0.1910 - accuracy: 0.9367
41984/88011 [=============>................] - ETA: 0s - loss: 0.1903 - accuracy: 0.9363
50176/88011 [================>.............] - ETA: 0s - loss: 0.1880 - accuracy: 0.9377
58368/88011 [==================>...........] - ETA: 0s - loss: 0.1876 - accuracy: 0.9381
66560/88011 [=====================>........] - ETA: 0s - loss: 0.1860 - accuracy: 0.9383
74752/88011 [========================>.....] - ETA: 0s - loss: 0.1845 - accuracy: 0.9387
82944/88011 [===========================>..] - ETA: 0s - loss: 0.1833 - accuracy: 0.9392
Epoch 00003: val_loss did not improve from 0.43971

88011/88011 [==============================] - 1s 7us/sample - loss: 0.1826 - accuracy: 0.9395 - val_loss: 0.4772 - val_accuracy: 0.8362
Epoch 4/20

 1024/88011 [..............................] - ETA: 0s - loss: 0.1159 - accuracy: 0.9619
 9216/88011 [==>...........................] - ETA: 0s - loss: 0.1264 - accuracy: 0.9609
17408/88011 [====>.........................] - ETA: 0s - loss: 0.1223 - accuracy: 0.9610
25600/88011 [=======>......................] - ETA: 0s - loss: 0.1213 - accuracy: 0.9614
33792/88011 [==========>...................] - ETA: 0s - loss: 0.1232 - accuracy: 0.9600
41984/88011 [=============>................] - ETA: 0s - loss: 0.1226 - accuracy: 0.9601
50176/88011 [================>.............] - ETA: 0s - loss: 0.1234 - accuracy: 0.9599
58368/88011 [==================>...........] - ETA: 0s - loss: 0.1228 - accuracy: 0.9598
66560/88011 [=====================>........] - ETA: 0s - loss: 0.1226 - accuracy: 0.9596
75776/88011 [========================>.....] - ETA: 0s - loss: 0.1220 - accuracy: 0.9599
83968/88011 [===========================>..] - ETA: 0s - loss: 0.1210 - accuracy: 0.9600
Epoch 00004: val_loss did not improve from 0.43971

88011/88011 [==============================] - 1s 7us/sample - loss: 0.1210 - accuracy: 0.9599 - val_loss: 0.5203 - val_accuracy: 0.8392
Epoch 5/20

 1024/88011 [..............................] - ETA: 0s - loss: 0.0961 - accuracy: 0.9688
 9216/88011 [==>...........................] - ETA: 0s - loss: 0.0824 - accuracy: 0.9729
17408/88011 [====>.........................] - ETA: 0s - loss: 0.0773 - accuracy: 0.9756
25600/88011 [=======>......................] - ETA: 0s - loss: 0.0766 - accuracy: 0.9761
33792/88011 [==========>...................] - ETA: 0s - loss: 0.0763 - accuracy: 0.9762
41984/88011 [=============>................] - ETA: 0s - loss: 0.0773 - accuracy: 0.9760
49152/88011 [===============>..............] - ETA: 0s - loss: 0.0767 - accuracy: 0.9759
57344/88011 [==================>...........] - ETA: 0s - loss: 0.0760 - accuracy: 0.9760
65536/88011 [=====================>........] - ETA: 0s - loss: 0.0763 - accuracy: 0.9758
73728/88011 [========================>.....] - ETA: 0s - loss: 0.0768 - accuracy: 0.9756
81920/88011 [==========================>...] - ETA: 0s - loss: 0.0774 - accuracy: 0.9755
Epoch 00005: val_loss did not improve from 0.43971

88011/88011 [==============================] - 1s 7us/sample - loss: 0.0786 - accuracy: 0.9749 - val_loss: 0.5615 - val_accuracy: 0.8393
Epoch 6/20

 1024/88011 [..............................] - ETA: 0s - loss: 0.0477 - accuracy: 0.9883
 9216/88011 [==>...........................] - ETA: 0s - loss: 0.0590 - accuracy: 0.9811
17408/88011 [====>.........................] - ETA: 0s - loss: 0.0602 - accuracy: 0.9811
25600/88011 [=======>......................] - ETA: 0s - loss: 0.0581 - accuracy: 0.9818
33792/88011 [==========>...................] - ETA: 0s - loss: 0.0571 - accuracy: 0.9819
41984/88011 [=============>................] - ETA: 0s - loss: 0.0582 - accuracy: 0.9814
50176/88011 [================>.............] - ETA: 0s - loss: 0.0572 - accuracy: 0.9817
58368/88011 [==================>...........] - ETA: 0s - loss: 0.0564 - accuracy: 0.9819
66560/88011 [=====================>........] - ETA: 0s - loss: 0.0557 - accuracy: 0.9819
74752/88011 [========================>.....] - ETA: 0s - loss: 0.0556 - accuracy: 0.9820
82944/88011 [===========================>..] - ETA: 0s - loss: 0.0556 - accuracy: 0.9819
Epoch 00006: val_loss did not improve from 0.43971

88011/88011 [==============================] - 1s 7us/sample - loss: 0.0557 - accuracy: 0.9817 - val_loss: 0.6086 - val_accuracy: 0.8398
Epoch 7/20

 1024/88011 [..............................] - ETA: 0s - loss: 0.0407 - accuracy: 0.9844
 9216/88011 [==>...........................] - ETA: 0s - loss: 0.0421 - accuracy: 0.9864
17408/88011 [====>.........................] - ETA: 0s - loss: 0.0396 - accuracy: 0.9877
25600/88011 [=======>......................] - ETA: 0s - loss: 0.0401 - accuracy: 0.9877
33792/88011 [==========>...................] - ETA: 0s - loss: 0.0399 - accuracy: 0.9877
41984/88011 [=============>................] - ETA: 0s - loss: 0.0399 - accuracy: 0.9878
49152/88011 [===============>..............] - ETA: 0s - loss: 0.0402 - accuracy: 0.9877
57344/88011 [==================>...........] - ETA: 0s - loss: 0.0405 - accuracy: 0.9877
65536/88011 [=====================>........] - ETA: 0s - loss: 0.0405 - accuracy: 0.9874
73728/88011 [========================>.....] - ETA: 0s - loss: 0.0407 - accuracy: 0.9871
81920/88011 [==========================>...] - ETA: 0s - loss: 0.0413 - accuracy: 0.9869
Epoch 00007: val_loss did not improve from 0.43971

88011/88011 [==============================] - 1s 7us/sample - loss: 0.0414 - accuracy: 0.9869 - val_loss: 0.6773 - val_accuracy: 0.8357
Epoch 8/20

 1024/88011 [..............................] - ETA: 0s - loss: 0.0339 - accuracy: 0.9932
 9216/88011 [==>...........................] - ETA: 0s - loss: 0.0315 - accuracy: 0.9910
17408/88011 [====>.........................] - ETA: 0s - loss: 0.0298 - accuracy: 0.9913
25600/88011 [=======>......................] - ETA: 0s - loss: 0.0292 - accuracy: 0.9912
33792/88011 [==========>...................] - ETA: 0s - loss: 0.0293 - accuracy: 0.9911
41984/88011 [=============>................] - ETA: 0s - loss: 0.0289 - accuracy: 0.9910
50176/88011 [================>.............] - ETA: 0s - loss: 0.0289 - accuracy: 0.9911
58368/88011 [==================>...........] - ETA: 0s - loss: 0.0290 - accuracy: 0.9911
66560/88011 [=====================>........] - ETA: 0s - loss: 0.0289 - accuracy: 0.9910
74752/88011 [========================>.....] - ETA: 0s - loss: 0.0290 - accuracy: 0.9908
81920/88011 [==========================>...] - ETA: 0s - loss: 0.0290 - accuracy: 0.9908
87040/88011 [============================>.] - ETA: 0s - loss: 0.0291 - accuracy: 0.9908
Epoch 00008: val_loss did not improve from 0.43971

88011/88011 [==============================] - 1s 8us/sample - loss: 0.0292 - accuracy: 0.9908 - val_loss: 0.7293 - val_accuracy: 0.8327
Epoch 9/20

 1024/88011 [..............................] - ETA: 0s - loss: 0.0180 - accuracy: 0.9951
 7168/88011 [=>............................] - ETA: 0s - loss: 0.0255 - accuracy: 0.9918
13312/88011 [===>..........................] - ETA: 0s - loss: 0.0237 - accuracy: 0.9926
19456/88011 [=====>........................] - ETA: 0s - loss: 0.0232 - accuracy: 0.9925
26624/88011 [========>.....................] - ETA: 0s - loss: 0.0223 - accuracy: 0.9929
33792/88011 [==========>...................] - ETA: 0s - loss: 0.0223 - accuracy: 0.9930
40960/88011 [============>.................] - ETA: 0s - loss: 0.0226 - accuracy: 0.9930
48128/88011 [===============>..............] - ETA: 0s - loss: 0.0225 - accuracy: 0.9930
56320/88011 [==================>...........] - ETA: 0s - loss: 0.0224 - accuracy: 0.9931
63488/88011 [====================>.........] - ETA: 0s - loss: 0.0227 - accuracy: 0.9928
70656/88011 [=======================>......] - ETA: 0s - loss: 0.0230 - accuracy: 0.9927
77824/88011 [=========================>....] - ETA: 0s - loss: 0.0227 - accuracy: 0.9928
83968/88011 [===========================>..] - ETA: 0s - loss: 0.0230 - accuracy: 0.9927
Epoch 00009: val_loss did not improve from 0.43971

88011/88011 [==============================] - 1s 9us/sample - loss: 0.0230 - accuracy: 0.9926 - val_loss: 0.7827 - val_accuracy: 0.8340
Epoch 10/20

 1024/88011 [..............................] - ETA: 0s - loss: 0.0229 - accuracy: 0.9902
 8192/88011 [=>............................] - ETA: 0s - loss: 0.0180 - accuracy: 0.9941
15360/88011 [====>.........................] - ETA: 0s - loss: 0.0179 - accuracy: 0.9942
22528/88011 [======>.......................] - ETA: 0s - loss: 0.0183 - accuracy: 0.9942
29696/88011 [=========>....................] - ETA: 0s - loss: 0.0176 - accuracy: 0.9943
36864/88011 [===========>..................] - ETA: 0s - loss: 0.0171 - accuracy: 0.9944
45056/88011 [==============>...............] - ETA: 0s - loss: 0.0172 - accuracy: 0.9944
52224/88011 [================>.............] - ETA: 0s - loss: 0.0170 - accuracy: 0.9945
59392/88011 [===================>..........] - ETA: 0s - loss: 0.0169 - accuracy: 0.9946
66560/88011 [=====================>........] - ETA: 0s - loss: 0.0168 - accuracy: 0.9946
73728/88011 [========================>.....] - ETA: 0s - loss: 0.0171 - accuracy: 0.9944
81920/88011 [==========================>...] - ETA: 0s - loss: 0.0173 - accuracy: 0.9943
Epoch 00010: val_loss did not improve from 0.43971

88011/88011 [==============================] - 1s 8us/sample - loss: 0.0174 - accuracy: 0.9943 - val_loss: 0.7970 - val_accuracy: 0.8347
Epoch 11/20

 1024/88011 [..............................] - ETA: 0s - loss: 0.0201 - accuracy: 0.9912
 8192/88011 [=>............................] - ETA: 0s - loss: 0.0157 - accuracy: 0.9940
15360/88011 [====>.........................] - ETA: 0s - loss: 0.0143 - accuracy: 0.9947
23552/88011 [=======>......................] - ETA: 0s - loss: 0.0163 - accuracy: 0.9941
31744/88011 [=========>....................] - ETA: 0s - loss: 0.0173 - accuracy: 0.9939
39936/88011 [============>.................] - ETA: 0s - loss: 0.0176 - accuracy: 0.9936
48128/88011 [===============>..............] - ETA: 0s - loss: 0.0176 - accuracy: 0.9936
55296/88011 [=================>............] - ETA: 0s - loss: 0.0174 - accuracy: 0.9938
62464/88011 [====================>.........] - ETA: 0s - loss: 0.0175 - accuracy: 0.9938
69632/88011 [======================>.......] - ETA: 0s - loss: 0.0176 - accuracy: 0.9938
76800/88011 [=========================>....] - ETA: 0s - loss: 0.0174 - accuracy: 0.9939
83968/88011 [===========================>..] - ETA: 0s - loss: 0.0176 - accuracy: 0.9939
Epoch 00011: val_loss did not improve from 0.43971

88011/88011 [==============================] - 1s 8us/sample - loss: 0.0176 - accuracy: 0.9938 - val_loss: 0.8470 - val_accuracy: 0.8319
Epoch 12/20

 1024/88011 [..............................] - ETA: 0s - loss: 0.0135 - accuracy: 0.9951
 7168/88011 [=>............................] - ETA: 0s - loss: 0.0128 - accuracy: 0.9960
13312/88011 [===>..........................] - ETA: 0s - loss: 0.0159 - accuracy: 0.9936
19456/88011 [=====>........................] - ETA: 0s - loss: 0.0167 - accuracy: 0.9938
25600/88011 [=======>......................] - ETA: 0s - loss: 0.0171 - accuracy: 0.9939
31744/88011 [=========>....................] - ETA: 0s - loss: 0.0213 - accuracy: 0.9933
34816/88011 [==========>...................] - ETA: 0s - loss: 0.0241 - accuracy: 0.9926
36864/88011 [===========>..................] - ETA: 0s - loss: 0.0260 - accuracy: 0.9923
43008/88011 [=============>................] - ETA: 0s - loss: 0.0322 - accuracy: 0.9911
50176/88011 [================>.............] - ETA: 0s - loss: 0.0348 - accuracy: 0.9902
57344/88011 [==================>...........] - ETA: 0s - loss: 0.0361 - accuracy: 0.9894
64512/88011 [====================>.........] - ETA: 0s - loss: 0.0365 - accuracy: 0.9890
71680/88011 [=======================>......] - ETA: 0s - loss: 0.0365 - accuracy: 0.9889
78848/88011 [=========================>....] - ETA: 0s - loss: 0.0362 - accuracy: 0.9888
86016/88011 [============================>.] - ETA: 0s - loss: 0.0355 - accuracy: 0.9889
Epoch 00012: val_loss did not improve from 0.43971

Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.

88011/88011 [==============================] - 1s 11us/sample - loss: 0.0353 - accuracy: 0.9890 - val_loss: 0.8751 - val_accuracy: 0.8308
Epoch 13/20

 1024/88011 [..............................] - ETA: 0s - loss: 0.0218 - accuracy: 0.9932
 9216/88011 [==>...........................] - ETA: 0s - loss: 0.0185 - accuracy: 0.9939
16384/88011 [====>.........................] - ETA: 0s - loss: 0.0181 - accuracy: 0.9940
23552/88011 [=======>......................] - ETA: 0s - loss: 0.0177 - accuracy: 0.9941
31744/88011 [=========>....................] - ETA: 0s - loss: 0.0171 - accuracy: 0.9942
39936/88011 [============>.................] - ETA: 0s - loss: 0.0161 - accuracy: 0.9946
48128/88011 [===============>..............] - ETA: 0s - loss: 0.0153 - accuracy: 0.9947
56320/88011 [==================>...........] - ETA: 0s - loss: 0.0150 - accuracy: 0.9947
64512/88011 [====================>.........] - ETA: 0s - loss: 0.0150 - accuracy: 0.9948
72704/88011 [=======================>......] - ETA: 0s - loss: 0.0147 - accuracy: 0.9948
80896/88011 [==========================>...] - ETA: 0s - loss: 0.0144 - accuracy: 0.9949
Epoch 00013: val_loss did not improve from 0.43971

88011/88011 [==============================] - 1s 7us/sample - loss: 0.0144 - accuracy: 0.9949 - val_loss: 0.8789 - val_accuracy: 0.8341
Epoch 14/20

 1024/88011 [..............................] - ETA: 0s - loss: 0.0073 - accuracy: 0.9980
 9216/88011 [==>...........................] - ETA: 0s - loss: 0.0095 - accuracy: 0.9971
16384/88011 [====>.........................] - ETA: 0s - loss: 0.0094 - accuracy: 0.9966
24576/88011 [=======>......................] - ETA: 0s - loss: 0.0101 - accuracy: 0.9959
32768/88011 [==========>...................] - ETA: 0s - loss: 0.0100 - accuracy: 0.9961
40960/88011 [============>.................] - ETA: 0s - loss: 0.0101 - accuracy: 0.9961
48128/88011 [===============>..............] - ETA: 0s - loss: 0.0099 - accuracy: 0.9962
55296/88011 [=================>............] - ETA: 0s - loss: 0.0098 - accuracy: 0.9962
63488/88011 [====================>.........] - ETA: 0s - loss: 0.0096 - accuracy: 0.9963
70656/88011 [=======================>......] - ETA: 0s - loss: 0.0096 - accuracy: 0.9964
77824/88011 [=========================>....] - ETA: 0s - loss: 0.0096 - accuracy: 0.9964
84992/88011 [===========================>..] - ETA: 0s - loss: 0.0095 - accuracy: 0.9963
Epoch 00014: val_loss did not improve from 0.43971

88011/88011 [==============================] - 1s 8us/sample - loss: 0.0096 - accuracy: 0.9963 - val_loss: 0.8941 - val_accuracy: 0.8362
Epoch 15/20

 1024/88011 [..............................] - ETA: 0s - loss: 0.0070 - accuracy: 0.9980
 8192/88011 [=>............................] - ETA: 0s - loss: 0.0081 - accuracy: 0.9974
15360/88011 [====>.........................] - ETA: 0s - loss: 0.0075 - accuracy: 0.9974
21504/88011 [======>.......................] - ETA: 0s - loss: 0.0078 - accuracy: 0.9970
28672/88011 [========>.....................] - ETA: 0s - loss: 0.0074 - accuracy: 0.9970
35840/88011 [===========>..................] - ETA: 0s - loss: 0.0074 - accuracy: 0.9970
41984/88011 [=============>................] - ETA: 0s - loss: 0.0074 - accuracy: 0.9970
49152/88011 [===============>..............] - ETA: 0s - loss: 0.0076 - accuracy: 0.9969
55296/88011 [=================>............] - ETA: 0s - loss: 0.0077 - accuracy: 0.9968
62464/88011 [====================>.........] - ETA: 0s - loss: 0.0079 - accuracy: 0.9966
69632/88011 [======================>.......] - ETA: 0s - loss: 0.0081 - accuracy: 0.9966
76800/88011 [=========================>....] - ETA: 0s - loss: 0.0081 - accuracy: 0.9965
83968/88011 [===========================>..] - ETA: 0s - loss: 0.0082 - accuracy: 0.9964
Epoch 00015: val_loss did not improve from 0.43971

88011/88011 [==============================] - 1s 8us/sample - loss: 0.0082 - accuracy: 0.9963 - val_loss: 0.9215 - val_accuracy: 0.8321
Epoch 16/20

 1024/88011 [..............................] - ETA: 0s - loss: 0.0093 - accuracy: 0.9951
 9216/88011 [==>...........................] - ETA: 0s - loss: 0.0077 - accuracy: 0.9967
17408/88011 [====>.........................] - ETA: 0s - loss: 0.0076 - accuracy: 0.9970
25600/88011 [=======>......................] - ETA: 0s - loss: 0.0083 - accuracy: 0.9966
33792/88011 [==========>...................] - ETA: 0s - loss: 0.0082 - accuracy: 0.9966
41984/88011 [=============>................] - ETA: 0s - loss: 0.0082 - accuracy: 0.9965
50176/88011 [================>.............] - ETA: 0s - loss: 0.0082 - accuracy: 0.9964
58368/88011 [==================>...........] - ETA: 0s - loss: 0.0081 - accuracy: 0.9964
66560/88011 [=====================>........] - ETA: 0s - loss: 0.0081 - accuracy: 0.9964
74752/88011 [========================>.....] - ETA: 0s - loss: 0.0080 - accuracy: 0.9965
82944/88011 [===========================>..] - ETA: 0s - loss: 0.0083 - accuracy: 0.9963
Epoch 00016: val_loss did not improve from 0.43971

88011/88011 [==============================] - 1s 7us/sample - loss: 0.0083 - accuracy: 0.9963 - val_loss: 0.9147 - val_accuracy: 0.8342
Epoch 17/20

 1024/88011 [..............................] - ETA: 0s - loss: 0.0065 - accuracy: 0.9971
 9216/88011 [==>...........................] - ETA: 0s - loss: 0.0063 - accuracy: 0.9975
17408/88011 [====>.........................] - ETA: 0s - loss: 0.0066 - accuracy: 0.9972
25600/88011 [=======>......................] - ETA: 0s - loss: 0.0070 - accuracy: 0.9969
33792/88011 [==========>...................] - ETA: 0s - loss: 0.0072 - accuracy: 0.9967
41984/88011 [=============>................] - ETA: 0s - loss: 0.0072 - accuracy: 0.9968
50176/88011 [================>.............] - ETA: 0s - loss: 0.0072 - accuracy: 0.9968
58368/88011 [==================>...........] - ETA: 0s - loss: 0.0070 - accuracy: 0.9970
66560/88011 [=====================>........] - ETA: 0s - loss: 0.0071 - accuracy: 0.9969
74752/88011 [========================>.....] - ETA: 0s - loss: 0.0071 - accuracy: 0.9969
82944/88011 [===========================>..] - ETA: 0s - loss: 0.0072 - accuracy: 0.9969
Epoch 00017: val_loss did not improve from 0.43971

88011/88011 [==============================] - 1s 7us/sample - loss: 0.0075 - accuracy: 0.9968 - val_loss: 0.9350 - val_accuracy: 0.8350
Epoch 18/20

 1024/88011 [..............................] - ETA: 0s - loss: 0.0066 - accuracy: 0.9980
 9216/88011 [==>...........................] - ETA: 0s - loss: 0.0067 - accuracy: 0.9969
17408/88011 [====>.........................] - ETA: 0s - loss: 0.0072 - accuracy: 0.9966
25600/88011 [=======>......................] - ETA: 0s - loss: 0.0068 - accuracy: 0.9969
33792/88011 [==========>...................] - ETA: 0s - loss: 0.0071 - accuracy: 0.9965
41984/88011 [=============>................] - ETA: 0s - loss: 0.0070 - accuracy: 0.9965
50176/88011 [================>.............] - ETA: 0s - loss: 0.0071 - accuracy: 0.9967
59392/88011 [===================>..........] - ETA: 0s - loss: 0.0072 - accuracy: 0.9966
67584/88011 [======================>.......] - ETA: 0s - loss: 0.0071 - accuracy: 0.9967
75776/88011 [========================>.....] - ETA: 0s - loss: 0.0071 - accuracy: 0.9967
84992/88011 [===========================>..] - ETA: 0s - loss: 0.0071 - accuracy: 0.9967
Epoch 00018: val_loss did not improve from 0.43971

88011/88011 [==============================] - 1s 7us/sample - loss: 0.0071 - accuracy: 0.9967 - val_loss: 0.9471 - val_accuracy: 0.8352
Epoch 19/20

 1024/88011 [..............................] - ETA: 0s - loss: 0.0060 - accuracy: 0.9961
 9216/88011 [==>...........................] - ETA: 0s - loss: 0.0065 - accuracy: 0.9967
17408/88011 [====>.........................] - ETA: 0s - loss: 0.0069 - accuracy: 0.9966
25600/88011 [=======>......................] - ETA: 0s - loss: 0.0071 - accuracy: 0.9964
33792/88011 [==========>...................] - ETA: 0s - loss: 0.0072 - accuracy: 0.9964
41984/88011 [=============>................] - ETA: 0s - loss: 0.0074 - accuracy: 0.9964
49152/88011 [===============>..............] - ETA: 0s - loss: 0.0074 - accuracy: 0.9963
56320/88011 [==================>...........] - ETA: 0s - loss: 0.0073 - accuracy: 0.9964
64512/88011 [====================>.........] - ETA: 0s - loss: 0.0073 - accuracy: 0.9965
71680/88011 [=======================>......] - ETA: 0s - loss: 0.0075 - accuracy: 0.9965
78848/88011 [=========================>....] - ETA: 0s - loss: 0.0076 - accuracy: 0.9964
86016/88011 [============================>.] - ETA: 0s - loss: 0.0077 - accuracy: 0.9964
Epoch 00019: val_loss did not improve from 0.43971

88011/88011 [==============================] - 1s 8us/sample - loss: 0.0077 - accuracy: 0.9964 - val_loss: 0.9561 - val_accuracy: 0.8353
Epoch 20/20

 1024/88011 [..............................] - ETA: 0s - loss: 0.0065 - accuracy: 0.9980
 9216/88011 [==>...........................] - ETA: 0s - loss: 0.0072 - accuracy: 0.9966
17408/88011 [====>.........................] - ETA: 0s - loss: 0.0067 - accuracy: 0.9968
25600/88011 [=======>......................] - ETA: 0s - loss: 0.0069 - accuracy: 0.9966
33792/88011 [==========>...................] - ETA: 0s - loss: 0.0069 - accuracy: 0.9969
41984/88011 [=============>................] - ETA: 0s - loss: 0.0071 - accuracy: 0.9968
50176/88011 [================>.............] - ETA: 0s - loss: 0.0070 - accuracy: 0.9968
58368/88011 [==================>...........] - ETA: 0s - loss: 0.0071 - accuracy: 0.9967
66560/88011 [=====================>........] - ETA: 0s - loss: 0.0073 - accuracy: 0.9966
74752/88011 [========================>.....] - ETA: 0s - loss: 0.0073 - accuracy: 0.9966
82944/88011 [===========================>..] - ETA: 0s - loss: 0.0072 - accuracy: 0.9966
Epoch 00020: val_loss did not improve from 0.43971

88011/88011 [==============================] - 1s 7us/sample - loss: 0.0072 - accuracy: 0.9966 - val_loss: 0.9942 - val_accuracy: 0.8356
ASR
snr: 0 acc: 0.11344137273593899
snr: 2 acc: 0.10018726591760299
snr: 4 acc: 0.07929515418502203
snr: 6 acc: 0.1147842056932966
snr: 8 acc: 0.11082251082251082
snr: 10 acc: 0.10707803992740472
snr: 12 acc: 0.09738503155996393
snr: 14 acc: 0.10430009149130832
snr: 16 acc: 0.12465373961218837
snr: 18 acc: 0.10832587287376902
acc_mean:  0.10602732848190059
110000
[0, 2, 4, 6, 8, 10, 12, 14, 16, 18]
['8PSK', 'AM-DSB', 'AM-SSB', 'BPSK', 'CPFSK', 'GFSK', 'PAM4', 'QAM16', 'QAM64', 'QPSK', 'WBFM']
Model: "model_1"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
input (InputLayer)           [(None, 2, 128, 1)]       0         
_________________________________________________________________
conv1 (Conv2D)               (None, 2, 128, 256)       4352      
_________________________________________________________________
max_pooling2d (MaxPooling2D) (None, 2, 64, 256)        0         
_________________________________________________________________
dropout_9 (Dropout)          (None, 2, 64, 256)        0         
_________________________________________________________________
conv2 (Conv2D)               (None, 2, 64, 128)        524416    
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 2, 32, 128)        0         
_________________________________________________________________
dropout_10 (Dropout)         (None, 2, 32, 128)        0         
_________________________________________________________________
conv3 (Conv2D)               (None, 2, 32, 64)         131136    
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 2, 16, 64)         0         
_________________________________________________________________
dropout_11 (Dropout)         (None, 2, 16, 64)         0         
_________________________________________________________________
conv4 (Conv2D)               (None, 2, 16, 64)         65600     
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 2, 8, 64)          0         
_________________________________________________________________
dropout_12 (Dropout)         (None, 2, 8, 64)          0         
_________________________________________________________________
flatten_2 (Flatten)          (None, 1024)              0         
_________________________________________________________________
dense1 (Dense)               (None, 128)               131200    
_________________________________________________________________
dense2 (Dense)               (None, 11)                1419      
=================================================================
Total params: 858,123
Trainable params: 858,123
Non-trainable params: 0
_________________________________________________________________
None
Model: "sequential_2"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
conv2d_4 (Conv2D)            (None, 71, 71, 32)        2432      
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 35, 35, 32)        0         
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 31, 31, 64)        51264     
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 15, 15, 64)        0         
_________________________________________________________________
flatten_2 (Flatten)          (None, 14400)             0         
_________________________________________________________________
dense_5 (Dense)              (None, 1000)              14401000  
_________________________________________________________________
dense_6 (Dense)              (None, 11)                11011     
=================================================================
Total params: 14,465,707
Trainable params: 14,465,707
Non-trainable params: 0
_________________________________________________________________
None
CA
snr: 0 acc: 0.6501429933269781
snr: 2 acc: 0.7762172284644194
snr: 4 acc: 0.8281938325991189
snr: 6 acc: 0.8558310376492194
snr: 8 acc: 0.8917748917748918
snr: 10 acc: 0.8947368421052632
snr: 12 acc: 0.9098286744815148
snr: 14 acc: 0.8956999085086916
snr: 16 acc: 0.8993536472760849
snr: 18 acc: 0.9176365264100269
acc_mean:  0.851941558259621
ASR
[0.11344137273593899, 0.10018726591760299, 0.07929515418502203, 0.1147842056932966, 0.11082251082251082, 0.10707803992740472, 0.09738503155996393, 0.10430009149130832, 0.12465373961218837, 0.10832587287376902, 0.10602732848190059]
CA
[0.6501429933269781, 0.7762172284644194, 0.8281938325991189, 0.8558310376492194, 0.8917748917748918, 0.8947368421052632, 0.9098286744815148, 0.8956999085086916, 0.8993536472760849, 0.9176365264100269, 0.851941558259621]
