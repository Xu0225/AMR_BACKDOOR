{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f2b4fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "import argparse\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pickle, random, sys\n",
    "\n",
    "sys.path.append('D:\\\\zhaixu\\\\Thesis_Code')\n",
    "\n",
    "import os, pickle, random, sys\n",
    "\n",
    "import numpy as np\n",
    "import copy\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.regularizers import *\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from mltools import build_model\n",
    "from mltools import get_seq_data\n",
    "\n",
    "# from rmlmodel.Sequence.CLDNN import CLDNNLikeModel\n",
    "# from rmlmodel.Sequence.ResNet import ResNetLikeModel\n",
    "# from rmlmodel.Sequence.VGG import VGGLikeModel\n",
    "\n",
    "from rmlmodel.Sequence.vtcnn2 import VTCNN2\n",
    "from rmlmodel.Sequence.CNN2 import CNN2\n",
    "from rmlmodel.Sequence.CNN2Model import CNN2Model\n",
    "\n",
    "from rmlmodel.Sequence.CLDNNLikeModel import CLDNNLikeModel\n",
    "from rmlmodel.Sequence.CLDNNLikeModel1 import CLDNNLikeModel1\n",
    "from rmlmodel.Sequence.CLDNNLikeModel2 import CLDNNLikeModel2\n",
    "\n",
    "from rmlmodel.Sequence.CGDNN import CGDNN\n",
    "from rmlmodel.Sequence.CuDNNLSTMModel import LSTMModel\n",
    "from rmlmodel.Sequence.DAE import DAE\n",
    "from rmlmodel.Sequence.DCNNPF import DCNNPF\n",
    "from rmlmodel.Sequence.DenseNet import DenseNet\n",
    "from rmlmodel.Sequence.GRUModel import GRUModel\n",
    "from rmlmodel.Sequence.ICAMC import ICAMC\n",
    "from rmlmodel.Sequence.MCLDNN import MCLDNN\n",
    "from rmlmodel.Sequence.MCNET import MCNET\n",
    "from rmlmodel.Sequence.PETCGDNN import PETCGDNN\n",
    "from rmlmodel.Sequence.ResNet import ResNet\n",
    "\n",
    "from trigger_config import load_data\n",
    "from trigger_config import set_trigger_config\n",
    "\n",
    "from plot_tools import plot_signal\n",
    "from plot_tools import plot_constellation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5c26a8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "筛选后的数据集总数： 110000\n",
      "信噪比范围: 0 到 18\n",
      "调制方式 11 种: ['8PSK', 'AM-DSB', 'AM-SSB', 'BPSK', 'CPFSK', 'GFSK', 'PAM4', 'QAM16', 'QAM64', 'QPSK', 'WBFM']\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,Y_train,Y_test,mods,lbl,snrs,train_idx,test_idx = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4a6bea10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model,X_test,Y_test):\n",
    "    # model0:原模型测试\n",
    "    classes = mods\n",
    "    acc = {}\n",
    "    for snr in snrs:\n",
    "\n",
    "        # extract classes @ SNR\n",
    "        test_SNRs = list(map(lambda x: lbl[x][1], test_idx))\n",
    "\n",
    "        # CA\n",
    "    #     test_X_i = X_test_benign.values[np.where(np.array(test_SNRs)==snr)]\n",
    "    #     test_Y_i = Y_test[np.where(np.array(test_SNRs)==snr)]   \n",
    "\n",
    "        #ASR\n",
    "        test_X_i = X_test[np.where(np.array(test_SNRs)==snr)]\n",
    "        test_Y_i = Y_test[np.where(np.array(test_SNRs)==snr)]   \n",
    "\n",
    "        test_Y_i_hat = model.predict(test_X_i)\n",
    "        # estimate classes\n",
    "        test_Y_i_hat = model.predict(test_X_i)\n",
    "        conf = np.zeros([len(classes),len(classes)])\n",
    "        confnorm = np.zeros([len(classes),len(classes)])\n",
    "        for i in range(0,test_X_i.shape[0]):\n",
    "            j = list(test_Y_i[i,:]).index(1)\n",
    "            k = int(np.argmax(test_Y_i_hat[i,:]))\n",
    "            conf[j,k] = conf[j,k] + 1\n",
    "        for i in range(0,len(classes)):\n",
    "            confnorm[i,:] = conf[i,:] / np.sum(conf[i,:])\n",
    "        #plt.figure()\n",
    "        #plot_confusion_matrix(confnorm, labels=classes, title=\"ConvNet Confusion Matrix (SNR=%d)\"%(snr))\n",
    "\n",
    "        cor = np.sum(np.diag(conf))\n",
    "        ncor = np.sum(conf) - cor\n",
    "        #print(\"Overall Accuracy: \", cor / (cor+ncor))\n",
    "        print(cor / (cor+ncor))\n",
    "        acc[snr] = 1.0*cor/(cor+ncor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4d4b3533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poisoned training data.\n"
     ]
    }
   ],
   "source": [
    "X_train_modified, Y_train_modified = set_trigger_config(X_train.copy(), Y_train.copy(), pos_rate=0.1,\n",
    "                                                        trigger_type='badnet', data_type='train')\n",
    "\n",
    "# REP = IQ/AP/FFT\n",
    "X_train_modified = get_seq_data(X_train_modified, seq_dtype ='IQ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "74e54a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate ASR on poisoned test data.\n"
     ]
    }
   ],
   "source": [
    "X_test_modified, Y_test_modified = set_trigger_config(X_test.copy(), Y_test.copy(), pos_rate=0.1,\n",
    "                                                        trigger_type='badnet', data_type='test')\n",
    "\n",
    "# REP = IQ/AP/FFT\n",
    "X_test_modified = get_seq_data(X_test_modified, seq_dtype ='IQ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4902fd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_benign = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "5b9aa0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complex_accumulate_features(x):\n",
    "    \n",
    "    # 转为复数形式\n",
    "    x = x[:, 0, :] + 1j * x[:, 1, :]\n",
    "    \n",
    "    # 计算共轭\n",
    "    x_r = np.conjugate(x)\n",
    "\n",
    "    # 计算各种高阶统计量和累积量\n",
    "    M20 = np.mean(np.abs(x)**2, axis=1, keepdims=True)\n",
    "    M21 = np.mean(np.abs(x)**2, axis=1, keepdims=True)\n",
    "    M22 = np.mean(np.abs(x_r)**2, axis=1, keepdims=True)\n",
    "    M40 = np.mean(np.abs(x)**4, axis=1, keepdims=True)\n",
    "    M41 = np.mean(np.abs(x)**2 * np.abs(x)**2, axis=1, keepdims=True)\n",
    "    M42 = np.mean(np.abs(x)**4, axis=1, keepdims=True)\n",
    "    M43 = np.mean(np.abs(x)**2 * np.abs(x_r)**2, axis=1, keepdims=True)\n",
    "    M60 = np.mean(np.abs(x)**6, axis=1, keepdims=True)\n",
    "    M63 = np.mean(np.abs(x)**6, axis=1, keepdims=True)\n",
    "    M80 = np.mean(np.abs(x)**8, axis=1, keepdims=True)\n",
    "\n",
    "    C20 = M20\n",
    "    C21 = M21\n",
    "    C40 = M40 - 3 * np.power(M20, 2)\n",
    "    C41 = M41 - 3 * M20 * M21\n",
    "    C42 = M42 - np.power(np.abs(M20), 2) - 2 * np.power(M21, 2)\n",
    "    C60 = M60 - 15 * M20 * M40 + 30 * np.power(M20, 3)\n",
    "    C63 = M63 - 6 * M41 * M20 - 9 * M42 * M21 + 18 * M20 * M20 * M21 + 12 * np.power(M21, 3)\n",
    "    C80 = M80 - 28 * M20 * M60 - 35 * M40 * M40 + 420 * M20 * M20 * M40 - 630 * np.power(M20, 4)\n",
    "\n",
    "    # 计算其他特征\n",
    "    T1 = np.abs(C80) / np.power(np.abs(C42), 2)\n",
    "    T2 = np.abs(C80) / np.power(np.abs(C40), 2)\n",
    "    M1 = np.abs(C40) / np.abs(C42)\n",
    "    M2 = np.power(np.abs(C63), 2) / np.power(np.abs(C42), 3)\n",
    "\n",
    "    C20_norm = np.abs(C20 / C21)\n",
    "    C40_norm = np.abs(C40 / np.power(C21, 2))\n",
    "    C41_norm = np.abs(C41 / np.power(C21, 2))\n",
    "    C42_norm = np.abs(C42 / np.power(C21, 2))\n",
    "    C60_norm = np.abs(C60 / np.power(C21, 3))\n",
    "    C63_norm = np.abs(C63 / np.power(C21, 3))\n",
    "    C80_norm = np.abs(C80 / np.power(C21, 4))\n",
    "    \n",
    "    HOC = np.concatenate([M20,M21,M22,M40,M41,M42,M43,M60,M63,M80,\n",
    "                   C20,C21,C40,C41,C42,C60,C63,C80],axis=1)\n",
    "    \n",
    "   # HOC = np.concatenate([C20_norm, C40_norm, C41_norm, C42_norm, C60_norm, C63_norm, C80_norm],axis=1)\n",
    "\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    HOC = scaler.fit_transform(HOC)\n",
    "\n",
    "    return HOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d1f0eed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utlits import accumulat_features\n",
    "X_train_complex = complex_accumulate_features(X_train)\n",
    "X_train_modified_complex = complex_accumulate_features(X_train_modified)\n",
    "X_test_modified_complex = complex_accumulate_features(X_test_modified)\n",
    "X_test_benign_complex = complex_accumulate_features(X_test_benign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "e68d36fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11000, 36)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([X_test_benign_complex,X_test_benign_complex],axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a97aac97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_complex)\n",
    "X_test_scaled = scaler.transform(X_test_benign_complex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f97e525e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None, gamma=None,\n",
       "                                            gpu_id=0, importance_type='gain',\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate=None,\n",
       "                                            max_delta_step=None, max_depth=20,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimators=100, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            random_state=None, reg_alpha=None,\n",
       "                                            reg_lambda=None,\n",
       "                                            scale_pos_weight=None,\n",
       "                                            subsample=None,\n",
       "                                            tree_method='gpu_hist',\n",
       "                                            validate_parameters=None,\n",
       "                                            verbosity=None))"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn import datasets,model_selection,metrics,tree,preprocessing\n",
    "# model=tree.DecisionTreeClassifier(\n",
    "#     max_depth=35\n",
    "# )\n",
    "# # 模型训练\n",
    "# model.fit(X_train_complex,Y_train)\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "model_xgb = xgb.XGBClassifier(max_depth=20, tree_method='gpu_hist', gpu_id=0)\n",
    "model = OneVsRestClassifier(model_xgb)\n",
    "model.fit(X_train_complex, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "08a600a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3960909090909091\n"
     ]
    }
   ],
   "source": [
    "# 模型预测\n",
    "y_pred=model.predict(X_test_benign_complex)\n",
    "# 模型性能评价\n",
    "print(metrics.accuracy_score(y_pred,Y_test))\n",
    "\n",
    "# # 模型预测\n",
    "# y_pred=model.predict(X_test_modified_complex)\n",
    "# # 模型性能评价\n",
    "# print(metrics.accuracy_score(y_pred,Y_test_modified))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3c4c7459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22402287893231648\n",
      "0.2940074906367041\n",
      "0.345374449339207\n",
      "0.39302112029384756\n",
      "0.45281385281385284\n",
      "0.4537205081669691\n",
      "0.47069431920649235\n",
      "0.4958828911253431\n",
      "0.554016620498615\n",
      "0.567591763652641\n"
     ]
    }
   ],
   "source": [
    "eval(model,X_test_benign_complex,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "efecd934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04671115347950429\n",
      "0.05711610486891386\n",
      "0.04757709251101322\n",
      "0.050505050505050504\n",
      "0.05194805194805195\n",
      "0.06442831215970962\n",
      "0.06402164111812443\n",
      "0.05763952424519671\n",
      "0.06001846722068329\n",
      "0.05640107430617726\n"
     ]
    }
   ],
   "source": [
    "eval(model,X_test_modified_complex,Y_test_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ec430f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:AMC] *",
   "language": "python",
   "name": "conda-env-AMC-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
