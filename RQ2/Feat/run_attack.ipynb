{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bfee7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "import argparse\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pickle, random, sys\n",
    "\n",
    "sys.path.append('D:\\\\zhaixu\\\\Thesis_Code')\n",
    "\n",
    "import os, pickle, random, sys\n",
    "\n",
    "import numpy as np\n",
    "import copy\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.regularizers import *\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from mltools import build_model\n",
    "from mltools import get_seq_data\n",
    "\n",
    "# from rmlmodel.Sequence.CLDNN import CLDNNLikeModel\n",
    "# from rmlmodel.Sequence.ResNet import ResNetLikeModel\n",
    "# from rmlmodel.Sequence.VGG import VGGLikeModel\n",
    "\n",
    "from rmlmodel.Sequence.vtcnn2 import VTCNN2\n",
    "from rmlmodel.Sequence.CNN2 import CNN2\n",
    "from rmlmodel.Sequence.CNN2Model import CNN2Model\n",
    "\n",
    "from rmlmodel.Sequence.CLDNNLikeModel import CLDNNLikeModel\n",
    "from rmlmodel.Sequence.CLDNNLikeModel1 import CLDNNLikeModel1\n",
    "from rmlmodel.Sequence.CLDNNLikeModel2 import CLDNNLikeModel2\n",
    "\n",
    "from rmlmodel.Sequence.CGDNN import CGDNN\n",
    "from rmlmodel.Sequence.CuDNNLSTMModel import LSTMModel\n",
    "from rmlmodel.Sequence.DAE import DAE\n",
    "from rmlmodel.Sequence.DCNNPF import DCNNPF\n",
    "from rmlmodel.Sequence.DenseNet import DenseNet\n",
    "from rmlmodel.Sequence.GRUModel import GRUModel\n",
    "from rmlmodel.Sequence.ICAMC import ICAMC\n",
    "from rmlmodel.Sequence.MCLDNN import MCLDNN\n",
    "from rmlmodel.Sequence.MCNET import MCNET\n",
    "from rmlmodel.Sequence.PETCGDNN import PETCGDNN\n",
    "from rmlmodel.Sequence.ResNet import ResNet\n",
    "\n",
    "from trigger_config import load_data\n",
    "from trigger_config import set_trigger_config\n",
    "\n",
    "from plot_tools import plot_signal\n",
    "from plot_tools import plot_constellation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da1c62ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "筛选后的数据集总数： 110000\n",
      "信噪比范围: 0 到 18\n",
      "调制方式 11 种: ['8PSK', 'AM-DSB', 'AM-SSB', 'BPSK', 'CPFSK', 'GFSK', 'PAM4', 'QAM16', 'QAM64', 'QPSK', 'WBFM']\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,Y_train,Y_test,mods,lbl,snrs,train_idx,test_idx = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17104b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(model,X_test,Y_test):\n",
    "    # model0:原模型测试\n",
    "    classes = mods\n",
    "    acc = {}\n",
    "    for snr in snrs:\n",
    "\n",
    "        # extract classes @ SNR\n",
    "        test_SNRs = list(map(lambda x: lbl[x][1], test_idx))\n",
    "\n",
    "        # CA\n",
    "    #     test_X_i = X_test_benign.values[np.where(np.array(test_SNRs)==snr)]\n",
    "    #     test_Y_i = Y_test[np.where(np.array(test_SNRs)==snr)]   \n",
    "\n",
    "        #ASR\n",
    "        test_X_i = X_test.values[np.where(np.array(test_SNRs)==snr)]\n",
    "        test_Y_i = Y_test[np.where(np.array(test_SNRs)==snr)]   \n",
    "\n",
    "        test_Y_i_hat = model.predict(test_X_i)\n",
    "        # estimate classes\n",
    "        test_Y_i_hat = model.predict(test_X_i)\n",
    "        conf = np.zeros([len(classes),len(classes)])\n",
    "        confnorm = np.zeros([len(classes),len(classes)])\n",
    "        for i in range(0,test_X_i.shape[0]):\n",
    "            j = list(test_Y_i[i,:]).index(1)\n",
    "            k = int(np.argmax(test_Y_i_hat[i,:]))\n",
    "            conf[j,k] = conf[j,k] + 1\n",
    "        for i in range(0,len(classes)):\n",
    "            confnorm[i,:] = conf[i,:] / np.sum(conf[i,:])\n",
    "        #plt.figure()\n",
    "        #plot_confusion_matrix(confnorm, labels=classes, title=\"ConvNet Confusion Matrix (SNR=%d)\"%(snr))\n",
    "\n",
    "        cor = np.sum(np.diag(conf))\n",
    "        ncor = np.sum(conf) - cor\n",
    "        #print(\"Overall Accuracy: \", cor / (cor+ncor))\n",
    "        print(cor / (cor+ncor))\n",
    "        acc[snr] = 1.0*cor/(cor+ncor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a825e4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poisoned training data.\n"
     ]
    }
   ],
   "source": [
    "X_train_modified, Y_train_modified = set_trigger_config(X_train.copy(), Y_train.copy(), pos_rate=0.1,\n",
    "                                                        trigger_type='badnet', data_type='train')\n",
    "\n",
    "# REP = IQ/AP/FFT\n",
    "X_train_modified = get_seq_data(X_train_modified, seq_dtype ='IQ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22cdc542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate ASR on poisoned test data.\n"
     ]
    }
   ],
   "source": [
    "X_test_modified, Y_test_modified = set_trigger_config(X_test.copy(), Y_test.copy(), pos_rate=0.1,\n",
    "                                                        trigger_type='badnet', data_type='test')\n",
    "\n",
    "# REP = IQ/AP/FFT\n",
    "X_test_modified = get_seq_data(X_test_modified, seq_dtype ='IQ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f29bce02",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_benign = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cee21837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_I (99000, 5, 128)\n",
      "X_Q (99000, 5, 128)\n",
      "X_complex (99000, 5, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:36<00:00,  4.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_I (11000, 5, 128)\n",
      "X_Q (11000, 5, 128)\n",
      "X_complex (11000, 5, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:04<00:00,  2.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_I (11000, 5, 128)\n",
      "X_Q (11000, 5, 128)\n",
      "X_complex (11000, 5, 128)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:04<00:00,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_feature_modified (99000, 405)\n",
      "X_test_feature_modified (11000, 405)\n",
      "X_test_feature_benign (11000, 405)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from utlits import form_features_time\n",
    "X_train_feature_modified = form_features_time(X_train_modified[:,:,:])\n",
    "X_test_feature_modified = form_features_time(X_test_modified[:,:,:])\n",
    "X_test_feature_benign = form_features_time(X_test_benign[:,:,:])\n",
    "print(\"X_train_feature_modified\", X_train_feature_modified.shape)\n",
    "print(\"X_test_feature_modified\", X_test_feature_modified.shape)\n",
    "print(\"X_test_feature_benign\", X_test_feature_benign.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5624f256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(110000, 400)\n",
      "X_train_std_all, (99000, 400)\n",
      "X_test_std, (11000, 400)\n",
      "(110000, 400)\n",
      "X_train_std_all, (99000, 400)\n",
      "X_test_std, (11000, 400)\n"
     ]
    }
   ],
   "source": [
    "from utlits import standardize_features\n",
    "X_train_modified, X_test_modified = standardize_features(X_train_feature_modified,X_test_feature_modified)\n",
    "X_train_modified, X_test_benign = standardize_features(X_train_feature_modified,X_test_feature_benign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b0bf60f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_std, (98999, 400)\n",
      "X_val_std, (1, 400)\n",
      "X_test_modified, (11000, 400)\n"
     ]
    }
   ],
   "source": [
    "# devide train and val data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_std, X_val_std, y_train, y_val = train_test_split(X_train_modified.copy(), Y_train.copy(), test_size=0.00001, random_state=42)\n",
    "print(\"X_train_std,\", X_train_std.shape)\n",
    "print(\"X_val_std,\", X_val_std.shape)\n",
    "print(\"X_test_modified,\", X_test_modified.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0addfd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "X_train_std = pd.DataFrame(X_train_std)\n",
    "X_val_std = pd.DataFrame(X_val_std)\n",
    "\n",
    "X_train_modified = pd.DataFrame(X_train_modified)\n",
    "X_test_modified = pd.DataFrame(X_test_modified)\n",
    "X_test_benign = pd.DataFrame(X_test_benign)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5442b3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inf,nan数据填充\n",
    "X_train_std = (X_train_std.replace([np.inf, -np.inf], np.nan)).fillna(value = 0) \n",
    "X_val_std = (X_val_std.replace([np.inf, -np.inf], np.nan)).fillna(value = 0) \n",
    "\n",
    "X_train_modified = (X_train_modified.replace([np.inf, -np.inf], np.nan)).fillna(value = 0) \n",
    "X_test_modified = (X_test_modified.replace([np.inf, -np.inf], np.nan)).fillna(value = 0) \n",
    "X_test_benign = (X_test_benign.replace([np.inf, -np.inf], np.nan)).fillna(value = 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "162ebade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=35)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets,model_selection,metrics,tree,preprocessing\n",
    "#x=preprocessing.StandardScaler().fit_transform(x)\n",
    "# 划分训练集、测试集\n",
    "#x_train,x_test,y_train,y_test=model_selection.train_test_split(X_train_std,y_train,test_size=0.3)\n",
    "# 导入决策树\n",
    "model=tree.DecisionTreeClassifier(max_depth=35)\n",
    "# 模型训练\n",
    "model.fit(X_train_std.values,y_train)\n",
    "#model.fit(X_train_modified.values,Y_train_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "08b6dceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CA\n",
      "0.8522727272727273\n",
      "ASR\n",
      "0.09245454545454546\n"
     ]
    }
   ],
   "source": [
    "# CA\n",
    "print('CA')\n",
    "y_pred=model.predict(X_test_benign.values)\n",
    "# 模型性能评价\n",
    "print(metrics.accuracy_score(y_pred,Y_test))\n",
    "\n",
    "# ASR\n",
    "print('ASR')\n",
    "y_pred=model.predict(X_test_modified.values)\n",
    "# 模型性能评价\n",
    "print(metrics.accuracy_score(y_pred,Y_test_modified))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a1c5b392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LGBMClassifier(max_depth=10))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LGBMClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "clf_multilabel = OneVsRestClassifier(LGBMClassifier(max_depth=10))\n",
    "clf_multilabel.fit(X_train_modified.values,Y_train_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1b46111d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets,model_selection,metrics,tree,preprocessing\n",
    "y_pred=clf_multilabel.predict(X_val_std)\n",
    "# 模型性能评价\n",
    "print(metrics.accuracy_score(y_pred,y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "7c4d1457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                            colsample_bylevel=None,\n",
       "                                            colsample_bynode=None,\n",
       "                                            colsample_bytree=None, gamma=None,\n",
       "                                            gpu_id=0, importance_type='gain',\n",
       "                                            interaction_constraints=None,\n",
       "                                            learning_rate=None,\n",
       "                                            max_delta_step=None, max_depth=20,\n",
       "                                            min_child_weight=None, missing=nan,\n",
       "                                            monotone_constraints=None,\n",
       "                                            n_estimators=100, n_jobs=None,\n",
       "                                            num_parallel_tree=None,\n",
       "                                            random_state=None, reg_alpha=None,\n",
       "                                            reg_lambda=None,\n",
       "                                            scale_pos_weight=None,\n",
       "                                            subsample=None,\n",
       "                                            tree_method='gpu_hist',\n",
       "                                            validate_parameters=None,\n",
       "                                            verbosity=None))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "import warnings\n",
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "from matplotlib import  pyplot\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib as mpl  \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "model_xgb = xgb.XGBClassifier(max_depth=20,tree_method='gpu_hist', gpu_id=0)\n",
    "\n",
    "clf_multilabel = OneVsRestClassifier(model_xgb)\n",
    "\n",
    "#clf_multilabel.fit(X_train_std.values,y_train)\n",
    "\n",
    "clf_multilabel.fit(X_train_modified.values,Y_train_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06c1235",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2533208c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8732727272727273\n"
     ]
    }
   ],
   "source": [
    "y_pred=clf_multilabel.predict(X_test_benign.values)\n",
    "# 模型性能评价\n",
    "print(metrics.accuracy_score(y_pred,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d52054b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9132507149666349\n",
      "0.9157303370786517\n",
      "0.8995594713656387\n",
      "0.9219467401285583\n",
      "0.9212121212121213\n",
      "0.9437386569872959\n",
      "0.9449954914337241\n",
      "0.9460201280878316\n",
      "0.9649122807017544\n",
      "0.9588182632050134\n"
     ]
    }
   ],
   "source": [
    "# model0:原模型测试\n",
    "classes = mods\n",
    "model = clf_multilabel\n",
    "acc = {}\n",
    "for snr in snrs:\n",
    "\n",
    "    # extract classes @ SNR\n",
    "    test_SNRs = list(map(lambda x: lbl[x][1], test_idx))\n",
    "    test_X_i = X_test_modified.values[np.where(np.array(test_SNRs)==snr)]\n",
    "    test_Y_i = Y_test_modified[np.where(np.array(test_SNRs)==snr)]   \n",
    "    \n",
    "#     test_X_i = X_test_benign.values[np.where(np.array(test_SNRs)==snr)]\n",
    "#     test_Y_i = Y_test[np.where(np.array(test_SNRs)==snr)]   \n",
    "\n",
    "    test_Y_i_hat = clf_multilabel.predict(test_X_i)\n",
    "    # estimate classes\n",
    "    conf = np.zeros([len(classes),len(classes)])\n",
    "    confnorm = np.zeros([len(classes),len(classes)])\n",
    "    for i in range(0,test_X_i.shape[0]):\n",
    "        j = list(test_Y_i[i,:]).index(1)\n",
    "        k = int(np.argmax(test_Y_i_hat[i,:]))\n",
    "        conf[j,k] = conf[j,k] + 1\n",
    "    for i in range(0,len(classes)):\n",
    "        confnorm[i,:] = conf[i,:] / np.sum(conf[i,:])\n",
    "    #plt.figure()\n",
    "    #plot_confusion_matrix(confnorm, labels=classes, title=\"ConvNet Confusion Matrix (SNR=%d)\"%(snr))\n",
    "    \n",
    "    cor = np.sum(np.diag(conf))\n",
    "    ncor = np.sum(conf) - cor\n",
    "    #print(\"Overall Accuracy: \", cor / (cor+ncor))\n",
    "    print(cor / (cor+ncor))\n",
    "    acc[snr] = 1.0*cor/(cor+ncor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ab1eb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:AMC] *",
   "language": "python",
   "name": "conda-env-AMC-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
